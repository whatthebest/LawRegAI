{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaVu3U2b2lmb",
        "outputId": "6694bd89-997b-4b04-dec6-87726fe97cca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (2.1.12)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.12/dist-packages (1.26.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.12/dist-packages (6.2.1)\n",
            "Requirement already satisfied: gspread-dataframe in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.12/dist-packages (0.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: langchain-core>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.3.78)\n",
            "Requirement already satisfied: google-ai-generativelanguage<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.11.10)\n",
            "Requirement already satisfied: filetype<2,>=1.2 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from gspread) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from gspread) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from gspread-dataframe) (2.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from gspread-dataframe) (1.17.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from bs4) (4.13.5)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.25.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.12.0->gspread) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.12.0->gspread) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.12.0->gspread) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (0.4.33)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->gspread-dataframe) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->gspread-dataframe) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->gspread-dataframe) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->bs4) (2.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.3.75->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.25.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.3.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "tesseract-ocr-tha is already the newest version (1:4.00~git30-7274cfa-1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# # ติดตั้งก่อน (ครั้งเดียวพอ)\n",
        "!pip install pytesseract pillow langchain-google-genai pymupdf transformers accelerate sentencepiece gspread gspread-dataframe bs4 PyMuPDF\n",
        "!apt-get install -y tesseract-ocr tesseract-ocr-tha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7PTxZSeZD1j"
      },
      "source": [
        "# **SETTING UP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcYC4aDDR-pj",
        "outputId": "05c98dcc-cf8c-4a5b-fa4a-768338bb4622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-16T00:51:20.697012] ✅ AI Model initialized successfully.\n"
          ]
        }
      ],
      "source": [
        "import bs4\n",
        "from bs4 import BeautifulSoup\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "from gspread_dataframe import get_as_dataframe,set_with_dataframe\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "import json\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import fitz  # PyMuPDF\n",
        "import requests\n",
        "import io\n",
        "import re\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "import re, json, gc, time\n",
        "from collections import Counter, defaultdict\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "# --- การตั้งค่า ---\n",
        "GOOGLE_API_KEY = \"AIzaSyBOhEb--Ri7jzOxpaRZPF-0u9T_5yLqu98\"\n",
        "\n",
        "\n",
        "def log_message(message):\n",
        "    print(f\"[{datetime.now().isoformat()}] {message}\")\n",
        "\n",
        "try:\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=GOOGLE_API_KEY)\n",
        "    log_message(\"✅ AI Model initialized successfully.\")\n",
        "except Exception as e:\n",
        "    log_message(f\"❌ Critical Error: Failed to initialize AI model: {e}\")\n",
        "    print(json.dumps({\"success\": False, \"message\": f\"Failed to initialize AI model: {e}\"}))\n",
        "\n",
        "\n",
        "def find_pdf_link_on_page(html_content, base_url):\n",
        "    log_message(\"   - Note: Content is HTML. Searching for PDF link...\")\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    for link in soup.find_all('a', href=True):\n",
        "        href = link['href']\n",
        "        if href.lower().endswith('.pdf'):\n",
        "            return urljoin(base_url, href)\n",
        "\n",
        "    return None\n",
        "\n",
        "# Authenticate with Google\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Authorize with Google Drive and Sheets\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "sheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/1lLxi-ziBMBhYzcI4ilnXG4IVkcQbwzV4k9xCRzrmh_w/edit')\n",
        "# Select the Lv3Law/RegulationName:กฎหมาย/กฎเกณฑ์/ประกาศ worksheet\n",
        "worksheet_DBR3 = sheet.worksheet('Lv3Law/RegulationName:กฎหมาย/กฎเกณฑ์/ประกาศ')\n",
        "\n",
        "# Step 1: Load existing data from the sheet into a DataFrame\n",
        "data_DBR3 = get_as_dataframe(worksheet_DBR3).dropna(how='all') # Drop completely empty rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHXjN5FhtRN2"
      },
      "source": [
        "# **Read PDF(Text-Base & OCR) + Clean_output**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UM6SUEN2VmP"
      },
      "outputs": [],
      "source": [
        "def _open_pdf(pdf_content):\n",
        "    \"\"\"รองรับทั้ง bytes และ path\"\"\"\n",
        "    if isinstance(pdf_content, (bytes, bytearray)):\n",
        "        return fitz.open(stream=pdf_content, filetype=\"pdf\")\n",
        "    elif isinstance(pdf_content, str):\n",
        "        return fitz.open(pdf_content)\n",
        "    else:\n",
        "        raise TypeError(\"pdf_content ต้องเป็น bytes/bytearray หรือ path (str)\")\n",
        "\n",
        "def _page_to_pil(page, dpi=300):\n",
        "    \"\"\"เรนเดอร์หน้า PDF เป็น PIL.Image (ใช้ matrix เพื่อรองรับทุกเวอร์ชันของ PyMuPDF)\"\"\"\n",
        "    zoom = dpi / 72.0\n",
        "    mat = fitz.Matrix(zoom, zoom)\n",
        "    pix = page.get_pixmap(matrix=mat, alpha=False)\n",
        "    return Image.open(io.BytesIO(pix.tobytes(\"png\")))\n",
        "\n",
        "def extract_text_per_page_hybrid(pdf_content, langs=\"tha+eng\", dpi=300, min_chars_page=60, ocr_psm=6):\n",
        "    \"\"\"\n",
        "    อ่านแบบผสมรายหน้า:\n",
        "      1) page.get_text(\"text\")\n",
        "      2) ถ้าสั้นกว่า min_chars_page -> OCR เฉพาะหน้านั้น\n",
        "    คืนค่า: (text รวมทั้งไฟล์, \"hybrid\")\n",
        "    \"\"\"\n",
        "    doc = _open_pdf(pdf_content)\n",
        "    parts = []\n",
        "    try:\n",
        "        for i, page in enumerate(doc, start=1):\n",
        "            log_message(f\"     - Processing page {i}/{len(doc)}...\")\n",
        "            # 1) text-first\n",
        "            txt = (page.get_text(\"text\") or \"\").strip()\n",
        "\n",
        "            if len(txt) < min_chars_page:\n",
        "                # 2) OCR เฉพาะหน้านี้\n",
        "                img = _page_to_pil(page, dpi=dpi)\n",
        "                cfg = f\"--oem 1 --psm {ocr_psm}\"\n",
        "                txt = pytesseract.image_to_string(img, lang=langs, config=cfg).strip()\n",
        "\n",
        "            parts.append(f\"\\n--- Page {i} ---\\n{txt}\")\n",
        "        full_text = \"\".join(parts).strip()\n",
        "        log_message(\"✅ Extract with hybrid\")\n",
        "        return full_text, \"hybrid\"\n",
        "    finally:\n",
        "        doc.close()\n",
        "\n",
        "def extract_text_with_fallback_mixed(pdf_content, min_chars_total=100, **kwargs):\n",
        "    \"\"\"\n",
        "    Wrapper สไตล์เดิม แต่ภายในใช้ per-page hybrid\n",
        "    \"\"\"\n",
        "    text, method = extract_text_per_page_hybrid(pdf_content, **kwargs)\n",
        "    if not text or len(text) < min_chars_total:\n",
        "        # เผื่อเอกสารหนักรูป/เบลอมากๆ จะลอง OCR ทุกหน้าอีกที (optional)\n",
        "        text_ocr_all = ocr_whole_pdf(pdf_content, **kwargs)\n",
        "        if len(text_ocr_all.strip()) > len(text.strip()):\n",
        "            log_message(\"✅ Extract with OCR\")\n",
        "            return text_ocr_all, \"ocr\"\n",
        "    log_message(\"✅ Extract with OCR\")\n",
        "    return text, method\n",
        "\n",
        "def ocr_whole_pdf(pdf_content, langs=\"tha+eng\", dpi=300, ocr_psm=6):\n",
        "    \"\"\"OCR ทุกหน้า (ใช้เมื่ออยากบังคับ OCR ทั้งไฟล์)\"\"\"\n",
        "    doc = _open_pdf(pdf_content)\n",
        "    out = []\n",
        "    try:\n",
        "        for page_num, page in enumerate(doc, start=1):\n",
        "            img = _page_to_pil(page, dpi=dpi)\n",
        "            cfg = f\"--oem 1 --psm {ocr_psm}\"\n",
        "            out.append(f\"\\n--- Page {page_num} ---\\n\" + pytesseract.image_to_string(img, lang=langs, config=cfg))\n",
        "            log_message(f\"     - OCR processing page {page_num + 1}/{len(doc)}...\")\n",
        "        return \"\".join(out)\n",
        "    finally:\n",
        "        doc.close()\n",
        "\n",
        "import re, unicodedata, io\n",
        "\n",
        "# อักขระไทยพื้นฐาน\n",
        "THAI = r\"\\u0E00-\\u0E7F\"\n",
        "THAI_CONS = \"กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผพภมยรฤลฦวศษสหฬอฮ\"\n",
        "\n",
        "# ----- 1) รายการคำ/พยางค์ที่ 'ควรเป็น ำ' (safe list) -----\n",
        "#   - จัดเฉพาะคำสั้น ๆ หรือพยางค์ต้นที่เจอบ่อยและแน่ใจว่าเป็น ำ\n",
        "SAFE_AM_WORDS = {\n",
        "    \"ทำ\", \"จำ\", \"นำ\", \"ขำ\", \"คำ\", \"งำ\", \"ชำ\", \"ดำ\", \"ตำ\",\n",
        "    \"รำ\", \"ลำ\", \"หำ\", \"อำ\", \"บำ\", \"ปำ\", \"ผำ\", \"พำ\", \"ภำ\", \"มำ\", \"ยำ\", \"วำ\",\n",
        "}\n",
        "\n",
        "# พยางค์นำแบบ “สำ-” ที่มักถูก OCR เป็น “สา-” แต่ควรเป็น “สำ-” (ระวัง \"สาขา\")\n",
        "SAFE_SAM_PREFIXES = {\n",
        "    # ใส่เฉพาะส่วนหลัง “สำ” (ไม่ต้องใส่ “สำ” เอง) ที่เจอบ่อย\n",
        "    \"คัญ\", \"นัก\", \"รวจ\", \"นิท\", \"นวน\", \"รอง\", \"เนา\", \"เร็\", \"หรับ\", \"ผัส\", \"มะโน\", \"หรั\", \"ราญ\",\n",
        "    \"นักงาน\", \"นักที่\", \"นักบัญชี\", \"นวนความ\", \"เนียง\", \"นึก\", \"นาก\", \"นาม\", \"นาอง\"  # เติม/แก้ตามงานจริงได้\n",
        "}\n",
        "\n",
        "# ----- 2) รายการ \"ยกเว้น\" ที่ต้องเป็น 'า' ไม่ใช่ 'ำ' (fix over-AM) -----\n",
        "#   - สำหรับคำที่มักโดน OCR เป็น ำ ทั้งที่ควรเป็น า\n",
        "OVERRIDE_TO_A = {\n",
        "    # ที่ผู้ใช้ยกตัวอย่าง\n",
        "    \"เทำ\": \"เทา\",\n",
        "    \"สาขำ\": \"สาขา\",\n",
        "\n",
        "    # คำพื้นฐานที่พบบ่อยในเอกสารราชการ/ธุรกิจ\n",
        "    \"กำร\": \"การ\",\n",
        "    \"ควำม\": \"ความ\",\n",
        "    \"สถำ\": \"สถา\",\n",
        "    \"ประกำศ\": \"ประกาศ\",\n",
        "    \"ประกำศ\": \"ประกาศ\",\n",
        "    \"พฤศจิกำยน\": \"พฤศจิกายน\",\n",
        "    \"ตำม\": \"ตาม\",         # เจอบ่อยมากในเอกสาร -> “ตาม”\n",
        "    \"หน้ำที่\": \"หน้าที่\",  # บางครั้ง ้ เพี้ยนร่วมด้วย (ถ้าไม่อยากแตะ ให้ลบอันนี้ออก)\n",
        "}\n",
        "\n",
        "# สำหรับ “พยางค์” ภายในคำ (ไม่ใช่คำเต็ม) ที่มักเพี้ยนเป็น ำ แต่ควรเป็น า\n",
        "OVERRIDE_SUBWORD_TO_A = {\n",
        "    \"ปฏิบัติกำร\": \"ปฏิบัติการ\",\n",
        "    \"ธนำคำร\": \"ธนาคาร\",\n",
        "    \"กำลัง\": \"กำลัง\",      # ตัวอย่างคงเดิม (กันการเผลอแก้กลับ)\n",
        "    \"คำสั่ง\": \"คำสั่ง\",     # คงเดิม (กันการเผลอแก้กลับ)\n",
        "}\n",
        "\n",
        "# ----- 3) regex ลัดสำหรับเคสมีช่องว่างแทรก เช่น “จ า/ท า/น า/ก าหนด” -----\n",
        "#    - จัดเป็น “จำ/ทำ/นำ/กำหนด” เฉพาะเคสที่ปลอดภัยและที่ผู้ใช้เจอจริง\n",
        "SPACEY_SAFE_FIXES = [\n",
        "    (re.compile(rf\"(?<![{THAI}])\\s*จ\\s*า(?![{THAI}])\"), \"จำ\"),\n",
        "    (re.compile(rf\"(?<![{THAI}])\\s*ท\\s*า(?![{THAI}])\"), \"ทำ\"),\n",
        "    (re.compile(rf\"(?<![{THAI}])\\s*น\\s*า(?![{THAI}])\"), \"นำ\"),\n",
        "    # “ก าหนด” → “กำหนด”\n",
        "    (re.compile(r\"ก\\s*า(?=หนด)\"), \"กำ\"),\n",
        "]\n",
        "\n",
        "# ตัวช่วย: รวม ํ + า → ำ\n",
        "COMBINE_MAITAIKHU_A = (re.compile(r\"\\u0E4D\\s*\\u0E32\"), \"\\u0E33\")  # ํ + า → ำ\n",
        "\n",
        "def _normalize(text: str) -> str:\n",
        "    text = unicodedata.normalize(\"NFC\", text or \"\")\n",
        "    # รวม ํ + า → ำ\n",
        "    text = re.sub(*COMBINE_MAITAIKHU_A, text)\n",
        "    # เก็บกวาดช่องว่างซ้ำ\n",
        "    text = re.sub(r\"[ \\t]{2,}\", \" \", text)\n",
        "    text = re.sub(r\"\\n[ \\t]+\", \"\\n\", text)\n",
        "    return text\n",
        "\n",
        "def _apply_spacey_safe_fixes(text: str) -> str:\n",
        "    for rx, rep in SPACEY_SAFE_FIXES:\n",
        "        text = rx.sub(rep, text)\n",
        "    return text\n",
        "\n",
        "def _apply_safe_am_words(text: str) -> str:\n",
        "    # แก้เฉพาะ “คำสั้นๆ” ที่อยู่โดด ๆ:  (จ\\s*า) → จำ   (มีขอบเขตคำแบบหยาบ)\n",
        "    for w in SAFE_AM_WORDS:\n",
        "        cons = w[0]\n",
        "        # จับทั้งแบบมีช่องว่าง “จ า” และไม่มีช่องว่าง “จา” เมื่อเป็น ‘คำโดด’\n",
        "        # \\b แบบ unicode ไม่นิ่งกับไทย ใช้ lookaround แทน\n",
        "        pat = re.compile(rf\"(?<![{THAI}]){cons}\\s*า(?![{THAI}])\")\n",
        "        text = pat.sub(w, text)\n",
        "    return text\n",
        "\n",
        "def _apply_safe_sam_prefix(text: str) -> str:\n",
        "    # แก้เฉพาะ “สา + <prefix จากลิสต์>” → “สำ + <prefix>”\n",
        "    for tail in sorted(SAFE_SAM_PREFIXES, key=len, reverse=True):\n",
        "        pat = re.compile(rf\"ส\\s*า\\s*{re.escape(tail)}\")\n",
        "        text = pat.sub(f\"สำ{tail}\", text)\n",
        "    return text\n",
        "\n",
        "def _apply_overrides(text: str) -> str:\n",
        "    # ยกเว้นแบบ “ทั้งคำ”\n",
        "    for wrong, right in OVERRIDE_TO_A.items():\n",
        "        # ยกเว้นแบบคำเต็ม (ขอบเขตโดยใช้ lookaround)\n",
        "        pat = re.compile(rf\"(?<![{THAI}]){re.escape(wrong)}(?![{THAI}])\")\n",
        "        text = pat.sub(right, text)\n",
        "    # ยกเว้นแบบ “ซับเวิร์ด” (แก้เป็นรายวลี)\n",
        "    for wrong, right in OVERRIDE_SUBWORD_TO_A.items():\n",
        "        text = text.replace(wrong, right)\n",
        "    return text\n",
        "\n",
        "def fix_thai_ocr(text: str) -> str:\n",
        "    \"\"\"\n",
        "    กลยุทธ์:\n",
        "      1) normalize + รวม ํ+า → ำ\n",
        "      2) แก้เคสมีช่องว่างแทรก (จ า/ท า/น า/ก าหนด)\n",
        "      3) เติม 'ำ' ให้คำ/พยางค์ที่ควรเป็น ำ (safe only)\n",
        "      4) เติม 'สำ-' ให้ prefix ที่ whitelist ไว้\n",
        "      5) ยกเว้น: แก้คำที่โดนใส่ ำ เกินเหตุ → กลับเป็น 'า'\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return text\n",
        "\n",
        "    text = _normalize(text)\n",
        "\n",
        "    # 2) เคสมีช่องว่างแทรก\n",
        "    text = _apply_spacey_safe_fixes(text)\n",
        "\n",
        "    # 3) เติม ำ ให้คำสั้นๆที่รู้ว่าใช่แน่\n",
        "    text = _apply_safe_am_words(text)\n",
        "\n",
        "    # 4) เติม “สำ-” ให้พยางค์นำที่ whitelist (เลี่ยง “สาขา” เพราะไม่อยู่ในลิสต์)\n",
        "    text = _apply_safe_sam_prefix(text)\n",
        "\n",
        "    # 5) คำยกเว้นที่ต้องกลับเป็น 'า'\n",
        "    text = _apply_overrides(text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EafPXEEVurSB"
      },
      "source": [
        "# **Multiple llm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "z3CLloTuSfDF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "from datetime import datetime\n",
        "from typing import List, Tuple, Optional, Dict, Any\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# ====== CONFIG ======\n",
        "FALLBACK_MODELS = [\n",
        "    \"gemini-2.5-flash\",       # ตัวหลัก เริ่มจากตัวนี้เสมอทุกครั้งที่เรียก\n",
        "    \"gemini-2.5-flash-lite\",\n",
        "    \"gemini-2.0-flash\"\n",
        "]\n",
        "DEFAULT_MAX_RETRIES_PER_MODEL = 1         # เราเลือกลองสั้น ๆ แล้วข้ามไปตัวถัดไป\n",
        "DEFAULT_GLOBAL_TIMEOUT_SEC = 180\n",
        "\n",
        "def log_message(msg: str):\n",
        "    print(f\"[{datetime.now().isoformat()}] {msg}\")\n",
        "\n",
        "# ====== ERROR / RETRY HELPERS ======\n",
        "def parse_retry_delay_seconds(error_text: str) -> Optional[int]:\n",
        "    m = re.search(r\"retry_delay\\s*\\{\\s*seconds:\\s*(\\d+)\", error_text)\n",
        "    if m: return int(m.group(1))\n",
        "    m = re.search(r'\"retry_delay\"\\s*:\\s*\\{\\s*\"seconds\"\\s*:\\s*(\\d+)', error_text)\n",
        "    if m: return int(m.group(1))\n",
        "    try:\n",
        "        d = json.loads(error_text)\n",
        "        if isinstance(d, dict):\n",
        "            rd = d.get(\"retry_delay\") or {}\n",
        "            secs = rd.get(\"seconds\")\n",
        "            if isinstance(secs, int): return secs\n",
        "    except Exception:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "def is_quota_or_rate_limit_error(e: Exception) -> bool:\n",
        "    txt = str(e)\n",
        "    keys = [\"429\", \"ResourceExhausted\", \"rate limit\", \"quota\", \"exceeded\"]\n",
        "    return any(k.lower() in txt.lower() for k in keys)\n",
        "\n",
        "# ====== COOLDOWN REGISTRY (ข้ามคำสั่งเรียกได้ในโปรเซสเดียว) ======\n",
        "_MODEL_COOLDOWN_UNTIL: Dict[str, float] = {}\n",
        "\n",
        "def _now() -> float:\n",
        "    return time.time()\n",
        "\n",
        "def _is_on_cooldown(model: str) -> bool:\n",
        "    return _MODEL_COOLDOWN_UNTIL.get(model, 0) > _now()\n",
        "\n",
        "def _set_cooldown(model: str, seconds: float):\n",
        "    _MODEL_COOLDOWN_UNTIL[model] = max(_MODEL_COOLDOWN_UNTIL.get(model, 0), _now() + seconds)\n",
        "\n",
        "def _soonest_cooldown_remaining(models: List[str]) -> float:\n",
        "    if not models: return 0\n",
        "    t = min((_MODEL_COOLDOWN_UNTIL.get(m, 0) for m in models), default=0)\n",
        "    remain = t - _now()\n",
        "    return remain if remain > 0 else 0\n",
        "\n",
        "# ====== LLM INIT (ครั้งที่ต้องการ instance ถาวร) ======\n",
        "def init_llm_with_fallback(api_key: str, models: List[str] = FALLBACK_MODELS) -> Tuple[ChatGoogleGenerativeAI, str]:\n",
        "    last_err = None\n",
        "    for model in models:\n",
        "        try:\n",
        "            llm = ChatGoogleGenerativeAI(model=model, google_api_key=api_key)\n",
        "            log_message(f\"✅ Initialized model: {model}\")\n",
        "            return llm, model\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            log_message(f\"⚠️ Init failed for {model}: {e}\")\n",
        "    raise RuntimeError(f\"❌ No available model. Last error: {last_err}\")\n",
        "\n",
        "# ====== CIRCULAR INVOKE (เริ่มที่ตัวหลักเสมอ + คูลดาวน์ + วนลูป) ======\n",
        "def circular_invoke_with_cooldown(\n",
        "    api_key: str,\n",
        "    prompt: str,\n",
        "    models: List[str] = FALLBACK_MODELS,\n",
        "    max_retries_per_model: int = DEFAULT_MAX_RETRIES_PER_MODEL,\n",
        "    global_timeout_sec: int = DEFAULT_GLOBAL_TIMEOUT_SEC,\n",
        "    no_model_sleep_floor: float = 1.5,\n",
        "    no_model_sleep_cap: float = 30.0,\n",
        "):\n",
        "    \"\"\"\n",
        "    พฤติกรรม:\n",
        "      - ทุกครั้งเริ่มจาก models[0] เสมอ (ตัวหลัก)\n",
        "      - ถ้าเจอโควต้า/429 แล้วมี retry_delay → set cooldown ให้โมเดลนั้น แล้ว 'ข้ามไปตัวถัดไป'\n",
        "      - ถ้าลองครบทุกตัวและทุกตัวอยู่ในคูลดาวน์ → รอจนตัวที่ใกล้หมดคูลดาวน์ที่สุด (ไม่ต่ำกว่า floor และไม่เกิน cap) แล้วเริ่มใหม่จากตัวหลัก\n",
        "      - เกิน global timeout → โยน TimeoutError\n",
        "    \"\"\"\n",
        "    start = time.time()\n",
        "    last_error = None\n",
        "    n = len(models)\n",
        "\n",
        "    def _try_model(m: str):\n",
        "        nonlocal last_error\n",
        "        if _is_on_cooldown(m):\n",
        "            return None, \"cooldown\"\n",
        "\n",
        "        try:\n",
        "            llm = ChatGoogleGenerativeAI(model=m, google_api_key=api_key)\n",
        "        except Exception as e:\n",
        "            last_error = e\n",
        "            log_message(f\"⚠️ Cannot init {m}: {e}\")\n",
        "            _set_cooldown(m, 5)  # กันลูป\n",
        "            return None, \"init-fail\"\n",
        "\n",
        "        for attempt in range(1, max_retries_per_model + 1):\n",
        "            if time.time() - start > global_timeout_sec:\n",
        "                raise TimeoutError(\"⏱️ Global timeout exceeded\")\n",
        "            try:\n",
        "                log_message(f\"🎯 Using model: {m} (attempt {attempt})\")\n",
        "                resp = llm.invoke(prompt)\n",
        "                return resp, \"ok\"\n",
        "            except Exception as e:\n",
        "                last_error = e\n",
        "                if is_quota_or_rate_limit_error(e):\n",
        "                    delay = parse_retry_delay_seconds(str(e))\n",
        "                    if delay is None:\n",
        "                        delay = min(2 ** (attempt - 1), 16) + random.uniform(0, 0.5)\n",
        "                    _set_cooldown(m, delay)\n",
        "                    log_message(f\"⏳ {m} quota/rate-limit → cooldown {delay:.1f}s, move on\")\n",
        "                    return None, \"rate-limit\"\n",
        "                else:\n",
        "                    log_message(f\"❌ {m} non-rate-limit error: {e}\")\n",
        "                    _set_cooldown(m, 3)\n",
        "                    return None, \"non-quota-error\"\n",
        "        return None, \"exhausted\"\n",
        "\n",
        "    while True:\n",
        "        if time.time() - start > global_timeout_sec:\n",
        "            raise TimeoutError(f\"⏱️ Global timeout exceeded. Last error: {last_error}\")\n",
        "\n",
        "        made_any_attempt = False\n",
        "        for m in models:  # เริ่มจากตัวแรกเสมอ\n",
        "            resp, status = _try_model(m)\n",
        "            if status == \"ok\":\n",
        "                return resp, m\n",
        "            if status != \"cooldown\":\n",
        "                made_any_attempt = True\n",
        "\n",
        "        if not made_any_attempt:\n",
        "            wait_for = _soonest_cooldown_remaining(models)\n",
        "            wait_for = max(wait_for, no_model_sleep_floor)\n",
        "            wait_for = min(wait_for, no_model_sleep_cap)\n",
        "            log_message(f\"😴 all models cooling down → sleep {wait_for:.1f}s\")\n",
        "            time.sleep(wait_for)\n",
        "        else:\n",
        "            # มีความพยายามแล้วแต่ยังไม่สำเร็จ → วนใหม่เริ่มที่ตัวหลัก\n",
        "            continue\n",
        "\n",
        "# ====== JSON-SAFE WRAPPER (ใช้ circular fallback) ======\n",
        "def _clean_json_block(text: str) -> str:\n",
        "    cleaned = text.strip()\n",
        "    cleaned = cleaned.replace(\"```json\", \"```\").strip()\n",
        "    cleaned = cleaned.strip(\"`\").strip()\n",
        "    if cleaned.lower().startswith(\"json\"):\n",
        "        cleaned = cleaned[4:].strip()\n",
        "    return cleaned\n",
        "\n",
        "def call_llm_json_with_circular_fallback(api_key: str, prompt: str):\n",
        "    resp, model_used = circular_invoke_with_cooldown(api_key, prompt)\n",
        "    raw = resp.content if hasattr(resp, \"content\") else str(resp)\n",
        "    cleaned = _clean_json_block(raw)\n",
        "    try:\n",
        "        return json.loads(cleaned), model_used\n",
        "    except Exception as e:\n",
        "        raise ValueError(\n",
        "            f\"JSON parse failed from model {model_used}: {e}\\nRaw (first 600 chars): {cleaned[:600]}\"\n",
        "        )\n",
        "\n",
        "# ====== CHUNKING ======\n",
        "def split_into_chunks(text: str, max_chars: int = 7000, overlap: int = 300) -> List[str]:\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    n = len(text)\n",
        "    while start < n:\n",
        "        end = min(start + max_chars, n)\n",
        "        chunks.append(text[start:end])\n",
        "        if end >= n:\n",
        "            break\n",
        "        start = max(0, end - overlap)\n",
        "    return chunks\n",
        "\n",
        "# ====== PROMPTS LV3 ======\n",
        "MAP_PROMPT_LV3 = \"\"\"คุณคือผู้ช่วยสกัดข้อมูลกฎหมาย/ประกาศ จงอ่านข้อความต่อไปนี้แล้วสกัดข้อมูลเป็น JSON เท่านั้น\n",
        "\n",
        "--- TEXT START ---\n",
        "{chunk}\n",
        "--- TEXT END ---\n",
        "\n",
        "จงตอบกลับเป็น JSON object ที่มีคีย์ดังนี้:\n",
        "  - \"Law/Regulation Name\": เลขของประกาศตามด้วย เรื่องของประกาศ (เช่น การปรับปรุงหลักเกณฑ์...)\n",
        "  - \"Source Type\": ประเภทของประกาศ (ระบุได้แค่ \"กฎเกณฑ์\" หรือ \"กฎหมาย\" เท่านั้น)\n",
        "  - \"Regulator Name\": หน่วยงานที่ออกประกาศ (เช่น ธนาคารแห่งประเทศไทย, สำนักงาน ก.ล.ต.)\n",
        "  - \"วันที่ประกาศ\": วันที่ประกาศ (ถ้าไม่พบ ให้ระบุว่า \"ไม่ระบุ\")\n",
        "  - \"วันที่มีผลบังคับใช้\": วันที่มีผลบังคับใช้ (ถ้าไม่พบ ให้ระบุว่า \"ไม่ระบุ\")\n",
        "  - \"วัตถุประสงค์ของกฎหมาย/กฎเกณฑ์/ประกาศ\": สรุปสาระสำคัญของประกาศ\n",
        "  - \"สรุปสาระสำคัญที่เปลี่ยนแปลง\": สรุปสาระสำคัญที่มีการเปลี่ยนแปลง (สรุปเป็นข้อๆ ถ้ามี)\n",
        "  - \"ผลกระทบ/สิ่งที่ธนาคารต้องดาเนินการ\":(ระบุได้แค่ \"มีผลกระทบ/มีสิ่งที่ธนาคารต้องดาเนินการ\", \"ไม่มีผลกระทบ/ไม่มีสิ่งที่ธนาคารต้องดำเนินการ\" หรือ \"ธนาคารยังไม่มีธุรกิจ/ธุรกรรม\" เท่านั้น)\n",
        "  - \"รายละเอียดผลกระทบ/สิ่งที่ธนาคารต้องดำเนินการ (เมื่อมีผลกระทบ/มีสิ่งที่ธนาคารต้องดาเนินการ)\":ระบุรายละเอียดผลกระทบ/สิ่งที่ธนาคารต้องดำเนินการ เมื่อมีผลกระทบ/มีสิ่งที่ธนาคารต้องดาเนินการ\n",
        "ข้อกำหนด:\n",
        "- ถ้าไม่พบข้อมูลบางคีย์ ให้ใส่ \"ไม่พบข้อมูล\"\n",
        "- ต้องเป็น JSON ที่ parse ได้เท่านั้น ห้ามมีข้อความอื่นปะปน\n",
        "\"\"\"\n",
        "\n",
        "# ====== PROMPTS LV4======\n",
        "MAP_PROMPT_LV4 = \"\"\"คุณคือผู้ช่วยสกัดข้อมูลกฎหมาย/ประกาศ จงอ่านข้อความต่อไปนี้แล้วสกัดข้อมูลเป็น JSON เท่านั้น\n",
        "\n",
        "--- TEXT START ---\n",
        "{chunk}\n",
        "--- TEXT END ---\n",
        "\n",
        "จงตอบกลับเป็น JSON object ที่มีคีย์ดังนี้:\n",
        "  - \"Law/Regulation Name\": เลขของประกาศตามด้วย เรื่องของประกาศ (เช่น การปรับปรุงหลักเกณฑ์...)\n",
        "  - \"Citation Name\": หลักเกณฑ์ในประกาศ (สรุปเป็นข้อๆ ถ้ามี ถ้าไม่พบ ให้ระบุว่า 'ไม่ระบุ')\n",
        "  - \"Citation Description\": รายละเอียดของหลักเกณฑ์ (ถ้ามีระบุ)\n",
        "  - \"วันที่กฎหมาย/กฎเกณฑ์กำหนดให้ดาเนินการแล้วเสร็จ\": วันที่กฎหมาย/กฎเกณฑ์กาหนดให้ดาเนินการแล้วเสร็จ\n",
        "  - \"โทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์\": (ระบุได้แค่ \"Composite Rating\", \" โทษปรับ\", \"โทษอาญา/จำคุก\", \"ระงับใบอนุญาตประกอบธุรกิจชั่วคราว\", \"ยกเลิก/เพิกถอนใบอนุญาตประกอบธุรกิจ\", \"ไม่มีโทษ/ผลกระทบ\" หรือ \"อื่นๆ\" เท่านั้น)\n",
        "  - \"โทษปรับสูงสุด (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษปรับ\")\": โทษปรับสูงสุด (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษปรับ\") (ถ้าไม่พบ ให้ระบุว่า \"ไม่ระบุ\")\n",
        "  - \"โทษปรับรายวัน (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษปรับ\")\": โทษปรับรายวัน (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษปรับ\") (ถ้าไม่พบ ให้ระบุว่า \"ไม่ระบุ\")\n",
        "  - \"โทษจำคุกสูงสุด (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษอาญา/จำคุก \")\": โทษจำคุกสูงสุด (เดือน) (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษอาญา/จำคุก \") (ถ้าไม่พบ ให้ระบุว่า \"ไม่ระบุ\")\n",
        "  - \"โทษจำคุกสูงสุด (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษอาญา/จำคุก \")\": โทษจำคุกสูงสุด (ปี) (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษอาญา/จำคุก \") (ถ้าไม่พบ ให้ระบุว่า \"ไม่ระบุ\")\n",
        "  - \"สิ่งที่ Risk Owner ต้องดำเนินการ\": (ระบุได้แค่ \"ประเมิน Gap Analysis และจัดทำ Action Plan (ถ้ามี)\", \"ทบทวน Gap Analysis และ/หรือ Action Plan เนื่องจากมีการเปลี่ยนแปลง/ยกเลิกกฎเกณฑ์\" หรือ \"ไม่ต้องดำเนินการ\" เท่านั้น)\n",
        "\n",
        "ข้อกำหนด:\n",
        "- ถ้าไม่พบข้อมูลบางคีย์ ให้ใส่ \"ไม่พบข้อมูล\"\n",
        "- ต้องเป็น JSON ที่ parse ได้เท่านั้น ห้ามมีข้อความอื่นปะปน\n",
        "\"\"\"\n",
        "\n",
        "REDUCE_PROMPT = \"\"\"รวมผล JSON หลายชิ้นให้เป็น JSON เดียว โดยคง schema เดิมทุก Keys\n",
        "กฏการรวม:\n",
        "- สำหรับฟิลด์ตัวอักษร: เลือกค่าที่ให้ภาพรวมดีที่สุด ถ้าหลายค่าไม่ขัดแย้งให้รวมสั้น ๆ เป็นข้อความเดียว\n",
        "- สำหรับ list เช่น \"Citation Name\", \"Citation Description\", \"สรุปสาระสำคัญที่เปลี่ยนแปลง\", \"รายละเอียดผลกระทบ/สิ่งที่ธนาคารต้องดำเนินการ (เมื่อมีผลกระทบ/มีสิ่งที่ธนาคารต้องดาเนินการ)\"\n",
        "  รวมและลบรายการซ้ำ\n",
        "- สรุปใจความสำคัญของแต่ละ Field อีกครั้งเพื่อความกระชับ และเพื่อประหยัดพื้นที่ในการจัดเก็บ\n",
        "- ถ้าฟิลด์ใดทั้งหมดเป็น \"ไม่พบข้อมูล\" ให้คง \"ไม่พบข้อมูล\"\n",
        "\n",
        "จงตอบกลับเป็น JSON เท่านั้น\n",
        "\n",
        "--- PARTS START ---\n",
        "{parts}\n",
        "--- PARTS END ---\n",
        "\"\"\"\n",
        "\n",
        "def merge_lists_unique(*lists) -> List[str]:\n",
        "    out = []\n",
        "    seen = set()\n",
        "    for lst in lists:\n",
        "        if isinstance(lst, list):\n",
        "            for item in lst:\n",
        "                if isinstance(item, str):\n",
        "                    key = item.strip()\n",
        "                    if key and key not in seen:\n",
        "                        seen.add(key)\n",
        "                        out.append(key)\n",
        "    return out\n",
        "\n",
        "def reduce_chunks(parts: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "    fields_text = [\n",
        "        \"Law/Regulation Name\",\n",
        "        \"Source Type\",\n",
        "        \"Regulator Name\",\n",
        "        \"Sequenced Number of Regulation\",\n",
        "        \"Effective Date\",\n",
        "        \"Objectives of the Law/Regulation/Announcements\",\n",
        "        \"Citation Description\",\n",
        "    ]\n",
        "    fields_list = [\n",
        "        \"Summary of Important Changes\",\n",
        "        \"Citation Name\",\n",
        "        \"สิ่งที่ธนาคารต้องดำเนินการ\",\n",
        "    ]\n",
        "\n",
        "    agg: Dict[str, Any] = {k: \"ไม่พบข้อมูล\" for k in fields_text}\n",
        "    for k in fields_list:\n",
        "        agg[k] = []\n",
        "\n",
        "    candidates: Dict[str, List[str]] = {k: [] for k in fields_text}\n",
        "\n",
        "    for p in parts:\n",
        "        for k in fields_text:\n",
        "            v = p.get(k)\n",
        "            if isinstance(v, str) and v.strip() and v.strip() != \"ไม่พบข้อมูล\":\n",
        "                candidates[k].append(v.strip())\n",
        "        for k in fields_list:\n",
        "            v = p.get(k)\n",
        "            if isinstance(v, list):\n",
        "                agg[k] = merge_lists_unique(agg[k], v)\n",
        "\n",
        "    for k in fields_text:\n",
        "        if candidates[k]:\n",
        "            agg[k] = max(candidates[k], key=len)\n",
        "    return agg\n",
        "\n",
        "# ====== CASE 1: ข้อความสั้น → ขอ JSON ตรง ๆ (ใช้วงกลม) ======\n",
        "def get_structured_data_from_ai(text: str) -> Dict[str, Any]:\n",
        "    prompt_LV3 = f\"\"\"\n",
        "    วิเคราะห์ข้อความจากเอกสารกฎหมายต่อไปนี้ และสกัดข้อมูลเพื่อเติมลงในช่องว่างเพื่อจัดเก็บประกาศ:\n",
        "\n",
        "    --- TEXT START ---\n",
        "    {text}\n",
        "    --- TEXT END ---\n",
        "\n",
        "  จงตอบกลับเป็น JSON object ที่มีคีย์ดังนี้:\n",
        "  - \"Law/Regulation Name\": เลขของประกาศตามด้วย เรื่องของประกาศ (เช่น การปรับปรุงหลักเกณฑ์...)\n",
        "  - \"Source Type\": ประเภทของประกาศ (ระบุได้แค่ \"กฎเกณฑ์\" หรือ \"กฎหมาย\" เท่านั้น)\n",
        "  - \"Regulator Name\": หน่วยงานที่ออกประกาศ (เช่น ธนาคารแห่งประเทศไทย, สำนักงาน ก.ล.ต.)\n",
        "  - \"วันที่ประกาศ\": วันที่ประกาศ (ถ้าไม่พบ ให้ระบุว่า \"ไม่ระบุ\")\n",
        "  - \"วันที่มีผลบังคับใช้\": วันที่มีผลบังคับใช้ (ถ้าไม่พบ ให้ระบุว่า \"ไม่ระบุ\")\n",
        "  - \"วัตถุประสงค์ของกฎหมาย/กฎเกณฑ์/ประกาศ\": สรุปสาระสำคัญของประกาศ\n",
        "  - \"สรุปสาระสำคัญที่เปลี่ยนแปลง\": สรุปสาระสำคัญที่มีการเปลี่ยนแปลง (สรุปเป็นข้อๆ ถ้ามี)\n",
        "  - \"ผลกระทบ/สิ่งที่ธนาคารต้องดาเนินการ\":(ระบุได้แค่ \"มีผลกระทบ/มีสิ่งที่ธนาคารต้องดำเนินการ\", \"ไม่มีผลกระทบ/ไม่มีสิ่งที่ธนาคารต้องดำเนินการ\" หรือ \"ธนาคารยังไม่มีธุรกิจ/ธุรกรรม\" เท่านั้น)\n",
        "  - \"รายละเอียดผลกระทบ/สิ่งที่ธนาคารต้องดำเนินการ (เมื่อมีผลกระทบ/มีสิ่งที่ธนาคารต้องดาเนินการ)\":ระบุรายละเอียดผลกระทบ/สิ่งที่ธนาคารต้องดำเนินการ เมื่อมีผลกระทบ/มีสิ่งที่ธนาคารต้องดาเนินการ\n",
        "ข้อกำหนด:\n",
        "- ถ้าไม่พบข้อมูลบางคีย์ ให้ใส่ \"ไม่พบข้อมูล\"\n",
        "- ต้องเป็น JSON ที่ parse ได้เท่านั้น ห้ามมีข้อความอื่นปะปน\n",
        "\"\"\"\n",
        "    prompt_LV4 = f\"\"\"\n",
        "    วิเคราะห์ข้อความจากเอกสารกฎหมายต่อไปนี้ และสกัดข้อมูลเพื่อเติมลงในช่องว่างเพื่อจัดเก็บประกาศ:\n",
        "\n",
        "    --- TEXT START ---\n",
        "    {text}\n",
        "    --- TEXT END ---\n",
        "\n",
        "  จงตอบกลับเป็น JSON object ที่มีคีย์ดังนี้:\n",
        "  - \"Law/Regulation Name\": เลขของประกาศตามด้วย เรื่องของประกาศ (เช่น การปรับปรุงหลักเกณฑ์...)\n",
        "  - \"Citation Name\": หลักเกณฑ์ในประกาศ (สรุปเป็นข้อๆ ถ้ามี ถ้าไม่พบ ให้ระบุว่า 'ไม่ระบุ')\n",
        "  - \"Citation Description\": รายละเอียดของหลักเกณฑ์ (ถ้ามีระบุ)\n",
        "  - \"วันที่กฎหมาย/กฎเกณฑ์กำหนดให้ดาเนินการแล้วเสร็จ\": วันที่กฎหมาย/กฎเกณฑ์กาหนดให้ดาเนินการแล้วเสร็จ\n",
        "  - \"โทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์\": (ระบุได้แค่ \"Composite Rating\", \" โทษปรับ\", \"โทษอาญา/จำคุก\", \"ระงับใบอนุญาตประกอบธุรกิจชั่วคราว\", \"ยกเลิก/เพิกถอนใบอนุญาตประกอบธุรกิจ\", \"ไม่มีโทษ/ผลกระทบ\" หรือ \"อื่นๆ\" เท่านั้น)\n",
        "  - \"โทษปรับสูงสุด (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษปรับ\")\": โทษปรับสูงสุด (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษปรับ\") (ถ้าไม่พบ ให้ระบุว่า \"ไม่ระบุ\")\n",
        "  - \"โทษปรับรายวัน (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษปรับ\")\": โทษปรับรายวัน (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษปรับ\") (ถ้าไม่พบ ให้ระบุว่า \"ไม่ระบุ\")\n",
        "  - \"โทษจำคุกสูงสุด (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษอาญา/จำคุก \")\": โทษจำคุกสูงสุด (เดือน) (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษอาญา/จำคุก \") (ถ้าไม่พบ ให้ระบุว่า \"ไม่ระบุ\")\n",
        "  - \"โทษจำคุกสูงสุด (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษอาญา/จำคุก \")\": โทษจำคุกสูงสุด (ปี) (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษอาญา/จำคุก \") (ถ้าไม่พบ ให้ระบุว่า \"ไม่ระบุ\")\n",
        "  - \"สิ่งที่ Risk Owner ต้องดำเนินการ\": (ระบุได้แค่ \"ประเมิน Gap Analysis และจัดทำ Action Plan (ถ้ามี)\", \"ทบทวน Gap Analysis และ/หรือ Action Plan เนื่องจากมีการเปลี่ยนแปลง/ยกเลิกกฎเกณฑ์\" หรือ \"ไม่ต้องดำเนินการ\" เท่านั้น)\n",
        "\n",
        "ข้อกำหนด:\n",
        "- ถ้าไม่พบข้อมูลบางคีย์ ให้ใส่ \"ไม่พบข้อมูล\"\n",
        "- ต้องเป็น JSON ที่ parse ได้เท่านั้น ห้ามมีข้อความอื่นปะปน\n",
        "\"\"\"\n",
        "\n",
        "    data_LV3, model_used = call_llm_json_with_circular_fallback(GOOGLE_API_KEY, prompt_LV3)\n",
        "    data_LV4, model_used = call_llm_json_with_circular_fallback(GOOGLE_API_KEY, prompt_LV4)\n",
        "    log_message(f\"✅ Short-text processed by {model_used}\")\n",
        "    return data_LV3,data_LV4\n",
        "\n",
        "# ====== CASE 2: ข้อความยาว → map-reduce (ใช้วงกลมในแต่ละ chunk) ======\n",
        "def get_structured_data_from_ai_large(text: str, max_chars=7000, overlap=500) -> Dict[str, Any]:\n",
        "    map_results_LV3 = []\n",
        "    map_results_LV4 = []\n",
        "    for i, chunk in enumerate(split_into_chunks(text, max_chars=max_chars, overlap=overlap), start=1):\n",
        "        prompt_LV3 = MAP_PROMPT_LV3.format(chunk=chunk)\n",
        "        try:\n",
        "            data_LV3, model_used_LV3 = call_llm_json_with_circular_fallback(GOOGLE_API_KEY, prompt_LV3)\n",
        "            data_LV3[\"chunk_id\"] = i\n",
        "            data_LV3[\"_model\"] = model_used_LV3\n",
        "            map_results_LV3.append(data_LV3)\n",
        "\n",
        "            log_message(f\"🧩 mapped chunk {i} via {model_used_LV3}\")\n",
        "        except Exception as e:\n",
        "            log_message(f\"❌ chunk {i} error: {e}\")\n",
        "            map_results_LV4.append({\"chunk_id\": i, \"error\": str(e)})\n",
        "\n",
        "        prompt_LV4 = MAP_PROMPT_LV4.format(chunk=chunk)\n",
        "        try:\n",
        "            data_LV4, model_used_LV4 = call_llm_json_with_circular_fallback(GOOGLE_API_KEY, prompt_LV4)\n",
        "            data_LV4[\"chunk_id\"] = i\n",
        "            data_LV4[\"_model\"] = model_used_LV4\n",
        "            map_results_LV4.append(data_LV4)\n",
        "            log_message(f\"🧩 mapped chunk {i} via {model_used_LV4}\")\n",
        "        except Exception as e:\n",
        "            log_message(f\"❌ chunk {i} error: {e}\")\n",
        "            map_results_LV4.append({\"chunk_id\": i, \"error\": str(e)})\n",
        "\n",
        "    clean_results_LV3 = [x for x in map_results_LV3 if \"error\" not in x]\n",
        "    if not clean_results_LV3:\n",
        "        return {\"error\": \"AI ไม่สามารถสกัดข้อมูลได้เลย\"}\n",
        "\n",
        "    merged_LV3 = reduce_chunks(clean_results_LV3)\n",
        "\n",
        "    clean_results_LV4 = [x for x in map_results_LV4 if \"error\" not in x]\n",
        "    if not clean_results_LV4:\n",
        "        return {\"error\": \"AI ไม่สามารถสกัดข้อมูลได้เลย\"}\n",
        "\n",
        "    merged_LV4 = reduce_chunks(clean_results_LV4)\n",
        "\n",
        "    # OPTIONAL: ให้ LLM ช่วยรวมขั้นสุดท้าย\n",
        "    try:\n",
        "        reduce_prompt_LV3 = REDUCE_PROMPT.format(parts=json.dumps(clean_results_LV3, ensure_ascii=False, indent=2))\n",
        "        final_json_LV3, model_used_LV3 = call_llm_json_with_circular_fallback(GOOGLE_API_KEY, reduce_prompt)\n",
        "        log_message(f\"✅ Reduced via {model_used_LV3}\")\n",
        "        reduce_prompt_LV4 = REDUCE_PROMPT.format(parts=json.dumps(clean_results_LV4, ensure_ascii=False, indent=2))\n",
        "        final_json_LV4, model_used_LV4 = call_llm_json_with_circular_fallback(GOOGLE_API_KEY, reduce_prompt)\n",
        "        return final_json_LV3,final_json_LV4\n",
        "    except Exception as e:\n",
        "        log_message(f\"⚠️ Reduce by LLM failed, fallback to programmatic merge: {e}\")\n",
        "        return merged_LV3,merged_LV4\n",
        "\n",
        "# ====== CASE SELECTOR ======\n",
        "def extract_structured_data(text: str, *, llm=None, threshold: int = 8000) -> Dict[str, Any]:\n",
        "    if len(text) <= threshold:\n",
        "        return get_structured_data_from_ai(text)\n",
        "    else:\n",
        "        return get_structured_data_from_ai_large(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umZFWDxJuilX"
      },
      "source": [
        "# **Converse Json to PD**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EzeurNz9L5s"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "# --- ตัวช่วยหลัก: แปลงค่าเป็นสตริงปลอดภัยสำหรับใส่ชีต ---\n",
        "def _to_safe_str(x: Any) -> str:\n",
        "    \"\"\"แปลงค่าให้เป็นสตริงปลอดภัย: None -> \"\", dict -> JSON, อย่างอื่น -> str().strip()\"\"\"\n",
        "    if x is None:\n",
        "        return \"\"\n",
        "    if isinstance(x, dict):\n",
        "        # serialize dict เป็น JSON เพื่อเลี่ยงการ .strip() กับ dict\n",
        "        return json.dumps(x, ensure_ascii=False)\n",
        "    return str(x).strip()\n",
        "\n",
        "def _to_sheet_bullets_formula(items: List[Any]) -> str:\n",
        "    \"\"\"\n",
        "    แปลง list ให้เป็นสูตร Google Sheet แบบขึ้นบรรทัด:\n",
        "    =\"• ข้อ1\" & CHAR(10) & \"• ข้อ2\"\n",
        "    \"\"\"\n",
        "    # แปลงทุกรายการเป็นข้อความเรียบก่อน\n",
        "    parts = [f'• {_to_safe_str(it)}' for it in items]\n",
        "    # ต่อด้วย \" & CHAR(10) & \"\n",
        "    return '=\"' + '\" & CHAR(10) & \"'.join(parts) + '\"'\n",
        "\n",
        "def _to_sheet_cell(x: Any, bullets_as_formula: bool = False) -> str:\n",
        "    \"\"\"\n",
        "    แปลงค่าหนึ่งช่องให้เหมาะกับ Google Sheet:\n",
        "    - None -> \"\"\n",
        "    - list -> bullet:\n",
        "        * ถ้า bullets_as_formula=True -> สูตร =\"• ...\" & CHAR(10) & ...\n",
        "        * ถ้า False -> ข้อความหลายบรรทัดด้วย \\n (ชีตจะแสดงเมื่อเปิด Wrap)\n",
        "    - dict -> JSON string\n",
        "    - อื่นๆ -> string.strip()\n",
        "    \"\"\"\n",
        "    if x is None:\n",
        "        return \"\"\n",
        "    if isinstance(x, list):\n",
        "        if len(x) == 0:\n",
        "            return \"\"\n",
        "        if bullets_as_formula:\n",
        "            return _to_sheet_bullets_formula(x)\n",
        "        # เป็นข้อความหลายบรรทัดธรรมดา (ต้องเปิด Wrap ในชีต)\n",
        "        return \"\\n\".join([f'• {_to_safe_str(it)}' for it in x])\n",
        "    if isinstance(x, dict):\n",
        "        return json.dumps(x, ensure_ascii=False)\n",
        "    return str(x).strip()\n",
        "\n",
        "# --- ฟังก์ชัน normalize record ตาม REQUIRED_KEYS ---\n",
        "def _normalize_record(rec: dict, REQUIRED_KEYS: List[str], bullets_as_formula: bool = True) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    - ให้ครบทุกคีย์ (ถ้าไม่มีให้ใส่ \"\")\n",
        "    - ถ้าค่าเป็น list ให้รวมเป็นบรรทัดละข้อด้วย '•'\n",
        "      * ถ้า bullets_as_formula=True จะได้เป็นสูตรชีต =\"…\" & CHAR(10) & \"…\"\n",
        "      * ถ้า False จะเป็นข้อความหลายบรรทัดคั่นด้วย \\n\n",
        "    - ค่าประเภทอื่นแปลงเป็นสตริงปลอดภัย\n",
        "    \"\"\"\n",
        "    out: Dict[str, str] = {}\n",
        "    for k in REQUIRED_KEYS:\n",
        "        v = rec.get(k, \"\")\n",
        "        out[k] = _to_sheet_cell(v, bullets_as_formula=bullets_as_formula)\n",
        "    return out\n",
        "\n",
        "# --- ตัวหลักที่คุณเรียกใช้ใน main ---\n",
        "def json_to_dataframe(data: Any, required_keys: List[str] = None, bullets_as_formula: bool = True) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    รับได้ทั้ง dict เดียว หรือ list ของ dicts\n",
        "    - รวมคีย์ทั้งหมด หรือใช้ required_keys ที่กำหนด\n",
        "    - บังคับค่าส่งออกเป็นสตริงที่ปลอดภัยต่อการอัปโหลดขึ้นชีต\n",
        "    \"\"\"\n",
        "    # จัดให้อยู่ในรูป list ของแถว\n",
        "    rows: List[dict]\n",
        "    if isinstance(data, list):\n",
        "        rows = data\n",
        "    elif isinstance(data, dict):\n",
        "        rows = [data]\n",
        "    else:\n",
        "        # ถ้า AI คืนอย่างอื่นมา (เช่น string) ก็ห่อเป็นคอลัมน์เดียว\n",
        "        rows = [{\"value\": data}]\n",
        "\n",
        "    # รวมคีย์ทั้งหมดถ้าไม่ได้กำหนด REQUIRED_KEYS\n",
        "    if required_keys is None:\n",
        "        keyset = set()\n",
        "        for r in rows:\n",
        "            if isinstance(r, dict):\n",
        "                keyset.update(r.keys())\n",
        "        REQUIRED_KEYS = sorted(keyset) if keyset else [\"value\"]\n",
        "    else:\n",
        "        REQUIRED_KEYS = list(required_keys)\n",
        "\n",
        "    # normalize ทุกแถว\n",
        "    norm_rows: List[Dict[str, str]] = []\n",
        "    for r in rows:\n",
        "        if not isinstance(r, dict):\n",
        "            r = {\"value\": r}\n",
        "        norm_rows.append(_normalize_record(r, REQUIRED_KEYS, bullets_as_formula=bullets_as_formula))\n",
        "\n",
        "    df = pd.DataFrame(norm_rows, columns=REQUIRED_KEYS)\n",
        "\n",
        "    # กันเหนียว: แปลงทุกช่องเป็น string อีกชั้น เผื่อมีหลุด\n",
        "    df = df.applymap(lambda x: \"\" if x is None else str(x))\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMutFQQmu0sD"
      },
      "source": [
        "# **Main Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05TCm88xrOsX"
      },
      "outputs": [],
      "source": [
        "def main(initial_url, llm=llm):\n",
        "    log_message(f\"🚀 Starting PDF processing for URL: {initial_url}\")\n",
        "    try:\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "\n",
        "        log_message(\" - Stage: Checking initial URL content type...\")\n",
        "        response = requests.get(initial_url, timeout=30, headers=headers, stream=True)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        content_type = response.headers.get('Content-Type', '').lower()\n",
        "        pdf_content = None\n",
        "\n",
        "        if 'text/html' in content_type:\n",
        "            log_message(\"   - Note: Content is HTML. Searching for PDF link...\")\n",
        "            html_content = response.content\n",
        "            found_url = find_pdf_link_on_page(html_content, initial_url)\n",
        "\n",
        "            if found_url:\n",
        "                pdf_url = found_url\n",
        "                log_message(f\"   - ✔️ Found PDF link: {pdf_url}. Downloading...\")\n",
        "                pdf_response = requests.get(pdf_url, timeout=30, headers=headers)\n",
        "                pdf_response.raise_for_status()\n",
        "                pdf_content = pdf_response.content\n",
        "            else:\n",
        "                raise ValueError(\"ไม่สามารถค้นหาลิงก์ PDF ในหน้าเว็บที่ระบุได้\")\n",
        "\n",
        "        elif 'application/pdf' in content_type or 'application/octet-stream' in content_type:\n",
        "            log_message(f\"   - Note: Direct download link found (Content-Type: {content_type}). Downloading content...\")\n",
        "            pdf_content = response.content\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported Content-Type: {content_type}\")\n",
        "\n",
        "        log_message(\" - ✔️ PDF content acquired.\")\n",
        "\n",
        "        text, method = extract_text_with_fallback_mixed(pdf_content)\n",
        "        log_message(f\" - ✔️ Text extracted with Method: {method}\")\n",
        "\n",
        "        Processed_text=fix_thai_ocr(text)\n",
        "        log_message(f\" - ✔️ Clean the output text\")\n",
        "\n",
        "        structured_data_LV3,structured_data_LV4 = extract_structured_data(Processed_text,llm=llm)\n",
        "        log_message(\"✅ Getting Answer LV3 from llm\")\n",
        "\n",
        "        # structured_data_LV4 = extract_structured_data_LV4(Processed_text,llm=llm)\n",
        "        # structured_data=json_to_dataframe(data)\n",
        "        if \"error\" in structured_data_LV3:\n",
        "             raise ValueError(f\"AI Error: {structured_data_LV3.get('details', structured_data_LV3['error'])}\")\n",
        "\n",
        "        if \"error\" in structured_data_LV4:\n",
        "             raise ValueError(f\"AI Error: {structured_data_LV4.get('details', structured_data_LV4['error'])}\")\n",
        "\n",
        "        log_message(\"✅ Processing finished successfully.\")\n",
        "\n",
        "        return structured_data_LV3,structured_data_LV4\n",
        "\n",
        "    except ValueError as ve:\n",
        "        error_message = str(ve)\n",
        "        log_message(f\"❌ A ValueError occurred: {error_message}\")\n",
        "        print(json.dumps({\"success\": False, \"message\": error_message}))\n",
        "\n",
        "    except requests.exceptions.RequestException as re:\n",
        "        error_message = f\"ไม่สามารถดาวน์โหลดไฟล์ PDF ได้: {re}\"\n",
        "        log_message(f\"❌ A RequestException occurred: {error_message}\")\n",
        "        print(json.dumps({\"success\": False, \"message\": error_message}))\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = str(e)\n",
        "        log_message(f\"❌ An unexpected error occurred in main function: {error_message}\")\n",
        "        print(json.dumps({\"success\": False, \"message\": f\"เกิดข้อผิดพลาดที่ไม่คาดคิด: {error_message}\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMplement"
      ],
      "metadata": {
        "id": "yIu8CgXcywbo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVf210M2hkAc"
      },
      "outputs": [],
      "source": [
        "# All_sum = [] # Initialize as a list to store dataframes\n",
        "# Reference = data_DBR3[\"URL(Source of reference for regulation change)\"]\n",
        "# Reference = Reference[1:]\n",
        "# for url in Reference:\n",
        "#     data = main(url)\n",
        "#     if data is not None: # Check if data is not None before processing\n",
        "#         data[\"URL_Ref.\"] = url\n",
        "#         summary_AI = json_to_dataframe(data)\n",
        "#         All_sum.append(summary_AI) # Append the dataframe to the list\n",
        "#     else:\n",
        "#         log_message(f\"Skipping URL due to processing error: {url}\")\n",
        "\n",
        "# # Concatenate all dataframes in the list outside the loop\n",
        "# if All_sum:\n",
        "#     DF_All = pd.concat(All_sum, ignore_index=True)\n",
        "# else:\n",
        "#     DF_All = pd.DataFrame() # Create an empty DataFrame if no dataframes were processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-GxJxMmzE1e"
      },
      "outputs": [],
      "source": [
        "# AI_lawreg = gc.open_by_url('https://docs.google.com/spreadsheets/d/1iJNbZTiqc5Ty1g-dbEALI4w8l2vYpRhBi2P1k_tksWQ/edit')\n",
        "# # Select the Lv3Law/RegulationName:กฎหมาย/กฎเกณฑ์/ประกาศ worksheet\n",
        "# worksheet_AIfill = AI_lawreg.worksheet('Data')\n",
        "\n",
        "# # Step 1: Load existing data from the sheet into a DataFrame\n",
        "# set_with_dataframe(worksheet_AIfill, DF_All)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wP5RvCZItdtS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ce0c09e-b71f-4935-cf16-08b3cb0fbcb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-16T00:51:24.905566]      - Processing page 1/2...\n",
            "[2025-10-16T00:51:51.898386]      - Processing page 2/2...\n",
            "[2025-10-16T00:52:03.741235] ✅ Extract with hybrid\n",
            "[2025-10-16T00:52:03.741633] ✅ Extract with OCR\n",
            "--- Page 1 ---\n",
            "ธนาคารแทห่งประเทศไทย |\n",
            "— 27 มกราคม 2560\n",
            "เรียน ผู้จัดการ\n",
            "ธนาคารพาณิชย์ทุกธนาคาร\n",
            "สถาบันการเงินเฉพาะกิจทุกแห่ง\n",
            "ที่ ธูปท.ฝตท.ว. /! /2560 เรื่อง แนวปฏิบัติในการรับลงทะเบียนพร้อมเพย์สำหรับนิติบุคคล\n",
            "ตามที่ธนาคารแห่งประเทศไทยได้ออกหนังสือเวียน ที่ ธปท.ฝตส.(03) ว807/2559 เรื่อง\n",
            "แนวปฏิบัติในการรับลงทะเบียนพร้อมเพย์ ลงวันที่ 29 มิถุนายน 2559 ซึ่งครอบคลุมการลงทะเบียนพร้อมเพย์\n",
            "สำหรับบุคคลธรรมดา และสถาบันการเงินจะเปิดให้บริการรับลงทะเบียนเพื่อใช้บริการโอนเงินและรับโอนเงิน\n",
            "แบบพร้อมเพย์สำหรับนิติบุคคลต่อไป นั้น\n",
            "เพื่อให้การรับลงทะเบียนนิติบุคคลมีความรัดกุม ปลอดภัย และถูกต้องเชื่อถือได้ อันจะช่วยลด\n",
            "ความเสี่ยงในการให้บริการของสถาบันการเงิน และเสริมสร้างความเชื่อมั่นแก่ผู้ใช้บริการ ธนาคารแห่งประเทศไทย\n",
            "จึงได้กำหนดแนวปฏิบัติอันเป็นมาตรฐานขั้นตำสำหรับกระบวนการรับลงทะเบียนนิติบุคคล ตามหลัก\n",
            "การพิสูจน์ตัวตนอย่างรัดกุม (Secured /เนปทอทน์๐น์อท) และการสร้างความน่าเชื่อถือในการทำธุรกรรม\n",
            "(Trusted Relationships) ดังนี้\n",
            "1. การระบุตัวตนและพิสูจน์ตัวตนของผู้ลงทะเบียน\n",
            "สถาบันการเงินต้องกำหนดกระบวนการที่มีความรัดกุมในการระบุตัวตน และตรวจสอบ\n",
            "ความถูกต้องของข้อมูล/เอกสารแสดงตนของนิติบุคคลผู้ลงทะเบียน ผู้มีอำนาจผูกพันนิติบุคคล และ\n",
            "ผู้กระทำการแทน ซึ่งต้องสอดคล้องกับวิธีปฏิบัติในปัจจุบันที่สถาบันการเงินใช้พิสูจน์ตัวตนในการทำธุรกรรม\n",
            "ทางการเงินกับนิติบุคคลด้วย ทั้งนี้ เอกสารประกอบการรับลงทะเบียนนิติบุคคล ควรประกอบด้วยหลักฐาน\n",
            "ดังต่อไปนี้\n",
            "1.1 ใบคำร้อง ข้อตกลงและเงื่อนไขในการใช้บริการ รวมถึงคำยินยอมให้เปิดเผยข้อมูล\n",
            "ซึ่งลงนามโดยผู้มีอำนาจลงนามผูกพันนิติบุคคล\n",
            "1.2 เอกสารหรือหลักฐานที่แสดงว่าบัญชีเงินฝากออมทรัพย์หรือกระแสรายวันที่ประสงค์\n",
            "จะลงทะเบียน มีนิติบุคคลผู้ลงทะเบียนเป็นเจ้าของบัญชี\n",
            "1.3 บัตรประชาชน หรือหนังสือเดินทาง (หรือสำเนา) ของผู้มีอำนาจลงนามแทนนิติบุคคล\n",
            "หรือผู้ที่เกี่ยวข้องสำหรับกรณีบุคคลที่มีการตกลงกันทางกฎหมาย ที่ได้รับมอบหมายหรือได้รับมอบอำนาจ\n",
            "ให้สร้างความสัมพันธ์ทางธุรกิจ เช่น กรรมการผู้มีอำนาจลงนาม ผู้มีอำนาจลงนามผูกพันนิติบุคคล ผู้มีอำนาจ\n",
            "สูงสุดของหน่วยงานกรณีเป็นหน่วยงานของรัฐ (พร้อมแนบหนังสือแต่งตั้งฯๆ) และผู้รับมอบอำนาจ\n",
            "1.4 หนังสือรับรองการจดทะเบียนนิติบุคคล ที่นายทะเบียนออกให้ไม่เกิน 3 เดือน หรือ\n",
            "เอกสารในการจัดตั้งนิติบุคคลตามที่สถาบันการเงินกำหนด\n",
            "1.5 บัตรประจำตัวผู้เสียภาษีอากร (ถ้ามี)\n",
            "1.6 หนังสือมอบอำนาจ (ถ้ามี) กรณีผู้มีอำนาจลงนามผูกพันนิติบุคคล ผู้มีอำนาจสูงสุด\n",
            "ของหน่วยงานกรณีเป็นหน่วยงานของรัฐ ไม่สามารถดำเนินการด้วยตนเอง ทั้งนี้ ขึ้นกับนโยบายการอนุญาต\n",
            "ให้มีผู้รับมอบอำนาจดำเนินการแทนของสถาบันการเงิน\n",
            "1.7 สถาบันการเงินอาจกำหนดหลักฐานอื่นเพิ่มเติมตามความจำเป็น\n",
            "วิสัยทัศน์ เป็นองค์กรที่มองไกล มีหลักการ และร่วมมือ เพื่อความเป็นอยู่ที่ดีอย่างยั่งยืนของไทย\n",
            "www .bot.or.th\n",
            "--- Page 2 ---\n",
            "2\n",
            "2. การตรวจสอบความถูกต้องเชื่อถือได้ของหมายเลขอ้างอิง (!0) ที่ใช้ลงทะเบียน\n",
            "สถาบันการเงินต้องตรวจสอบความถูกต้องของเลขประจำตัวผู้เสียภาษีอากรที่ใช้\n",
            "ลงทะเบียน ตามเกณฑ์การบริหารความเสี่ยงของสถาบันการเงิน\n",
            "3. การควบคุมความเสี่ยงของกระบวนการปฏิบัติงานที่เกี่ยวข้อง\n",
            "3.1 ก่อนรับลงทะเบียนทุกครั้ง สถาบันการเงินต้องแสดงเงื่อนไขการใช้บริการ (โอกการ\n",
            "and 6๐ทย์เพ์อทร) และขอคำยินยอมจากผู้ลงทะเบียนในการเปิดเผยข้อมูลที่เกี่ยวข้อง (๐๐ก5๑กป เพื่อให้\n",
            "ผู้ลงทะเบียนรับทราบข้อมูลอย่างครบถ้วน ถูกต้อง และชัดเจน ตลอดจนมีหลักฐานในการให้ความยินยอม\n",
            "แก่สถาบันการเงินในการเปิดเผยข้อมูลของตน\n",
            "3.2 ให้สถาบันการเงินแจ้งผลการลงทะเบียนให้ผู้ลงทะเบียนทราบเป็นลายลักษณ์อักษร\n",
            "ในรูปแบบเอกสารหรืออิเล็กทรอนิกส์ ทั้งกรณีลงทะเบียนสำเร็จและไม่สำเร็จ\n",
            "3.3 ในกรณีผู้ลงทะเบียนมีความประสงค์ที่จะขอเปลี่ยนแปลง แก้ไข หรือยกเลิก\n",
            "การลงทะเบียน ให้สถาบันการเงินพิสูจน์ตัวตนของผู้ลงทะเบียนด้วยความรัดกุม สอดคล้องกับวิธีปฏิบัติใน\n",
            "การพิสูจน์ตัวตนในขั้นตอนของการรับลงทะเบียนด้วย\n",
            "3.4 ให้สถาบันการเงินให้ข้อมูลและแนะนำลูกค้านิติบุคคลให้มีกระบวนการควบคุม\n",
            "ภายในที่ดีในเรื่องการใช้บริการพร้อมเพย์ นอกจากนี้ ให้สถาบันการเงินเตรียมความพร้อมเจ้าหน้าที่สาขา\n",
            "และ (ล[| (๑ทพอ ในการสื่อสารและตอบข้อซักถามลูกค้านิติบุคคลด้วย\n",
            "ทั้งนี้ หน่วยงานด้านการกำกับการปฏิบัติงานและด้านการตรวจสอบภายในของสถาบันการเงิน\n",
            "ต้องมีส่วนร่วมในการกำกับดูแลและสอบทานการปฏิบัติงาน ในกระบวนการรับลงทะเบียนของสถาบันการเงิน\n",
            "ให้เป็นไปตามมาตรฐานขั้นตำที่ธนาคารแห่งประเทศไทยกำหนด อย่างสม่าเสมอ\n",
            "จึงเรียนมาเพื่อโปรดทราบและถือปฏิบัติ\n",
            "ขอแสดงความนับถือ\n",
            "Arg 77 ny\n",
            "(นางสาวสิริธิดา พนมวัน ณ อยุธยา)\n",
            "ผู้ช่วยผู้ว่าการ สายนโยบายระบบการชำระเงิน\n",
            "และเทคโนโลยีทางการเงิน\n",
            "ผู้ว่าการ“ทน\n",
            "ฝ่ายตรวจสอบเทคโนโลยีสารสนเทศ\n",
            "โทรศัพท์ 0 2356 7614, 0 2283 5752\n",
            "โทรสาร 0 2356 7450\n",
            "[2025-10-16T00:52:03.754058] 🎯 Using model: gemini-2.5-flash (attempt 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 56.148498115s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 56\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 53.998091277s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 53\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 49.877869719s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 49\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 41.756082662s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 41\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\n",
            "Please retry in 25.614293656s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 250\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 25\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-16T00:53:06.599943] ⏳ gemini-2.5-flash quota/rate-limit → cooldown 53.0s, move on\n",
            "[2025-10-16T00:53:06.603505] 🎯 Using model: gemini-2.5-flash-lite (attempt 1)\n",
            "[2025-10-16T00:53:09.106315] 🎯 Using model: gemini-2.5-flash-lite (attempt 1)\n",
            "[2025-10-16T00:53:13.200941] ✅ Short-text processed by gemini-2.5-flash-lite\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-843406306.py:100: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: \"\" if x is None else str(x))\n"
          ]
        }
      ],
      "source": [
        "#------------------------------------------\n",
        "#. for Test on record\n",
        "#------------------------------------------\n",
        "\n",
        "\n",
        "# อ่าน PDF และแปลงเป็นภาพ\n",
        "# url = \"https://www.bot.or.th/content/dam/bot/fipcs/documents/FOG/2566/ThaiPDF/25660202.pdf\"\n",
        "url = \"https://www.bot.or.th/content/dam/bot/fipcs/documents/FPG/2560/ThaiPDF/25600025.pdf\"\n",
        "resp = requests.get(url)\n",
        "pdf_content = resp.content   # bytes จาก response\n",
        "\n",
        "text, method = extract_text_with_fallback_mixed(pdf_content)\n",
        "clean_text = fix_thai_ocr(text)\n",
        "print(clean_text)\n",
        "# -------------------------\n",
        "# ตัวอย่างใช้งาน:\n",
        "Processed_text=fix_thai_ocr(text)\n",
        "structured_data_LV3,structured_data_LV4 = extract_structured_data(Processed_text, llm=llm)\n",
        "summary_LV3_AI=json_to_dataframe(structured_data_LV3)\n",
        "summary_LV4_AI=json_to_dataframe(structured_data_LV4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3QNB33z3XBE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d87c91a3-cbc9-4c00-99b6-213e34ad1b0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                Citation Description Citation Name  \\\n",
              "0  ธนาคารแห่งประเทศไทยกำหนดแนวปฏิบัติอันเป็นมาตรฐ...       ไม่ระบุ   \n",
              "\n",
              "                                 Law/Regulation Name  \\\n",
              "0  ที่ ธูปท.ฝตท.ว. /! /2560 เรื่อง แนวปฏิบัติในกา...   \n",
              "\n",
              "  วันที่กฎหมาย/กฎเกณฑ์กำหนดให้ดำเนินการแล้วเสร็จ  \\\n",
              "0                                    ไม่พบข้อมูล   \n",
              "\n",
              "                    สิ่งที่ Risk Owner ต้องดำเนินการ  \\\n",
              "0  ประเมิน Gap Analysis และจัดทำ Action Plan (ถ้ามี)   \n",
              "\n",
              "  โทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์  \\\n",
              "0                                      อื่นๆ   \n",
              "\n",
              "  โทษจำคุกสูงสุด (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษอาญา/จำคุก \")  \\\n",
              "0                                            ไม่ระบุ                                            \n",
              "\n",
              "  โทษปรับรายวัน (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษปรับ\")  \\\n",
              "0                                            ไม่ระบุ                                    \n",
              "\n",
              "  โทษปรับสูงสุด (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษปรับ\")  \n",
              "0                                            ไม่ระบุ                                   "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52a9183c-113d-409c-ab96-94ffadd21db2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Citation Description</th>\n",
              "      <th>Citation Name</th>\n",
              "      <th>Law/Regulation Name</th>\n",
              "      <th>วันที่กฎหมาย/กฎเกณฑ์กำหนดให้ดำเนินการแล้วเสร็จ</th>\n",
              "      <th>สิ่งที่ Risk Owner ต้องดำเนินการ</th>\n",
              "      <th>โทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์</th>\n",
              "      <th>โทษจำคุกสูงสุด (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษอาญา/จำคุก \")</th>\n",
              "      <th>โทษปรับรายวัน (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษปรับ\")</th>\n",
              "      <th>โทษปรับสูงสุด (เมื่อเลือกโทษ/ผลกระทบกรณีไม่ปฏิบัติตามกฎหมาย/กฎเกณฑ์ เป็น \"โทษปรับ\")</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ธนาคารแห่งประเทศไทยกำหนดแนวปฏิบัติอันเป็นมาตรฐ...</td>\n",
              "      <td>ไม่ระบุ</td>\n",
              "      <td>ที่ ธูปท.ฝตท.ว. /! /2560 เรื่อง แนวปฏิบัติในกา...</td>\n",
              "      <td>ไม่พบข้อมูล</td>\n",
              "      <td>ประเมิน Gap Analysis และจัดทำ Action Plan (ถ้ามี)</td>\n",
              "      <td>อื่นๆ</td>\n",
              "      <td>ไม่ระบุ</td>\n",
              "      <td>ไม่ระบุ</td>\n",
              "      <td>ไม่ระบุ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52a9183c-113d-409c-ab96-94ffadd21db2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-52a9183c-113d-409c-ab96-94ffadd21db2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-52a9183c-113d-409c-ab96-94ffadd21db2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_953a6dca-4c14-4e1d-9aec-0e0123ff4a39\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('summary_LV4_AI')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_953a6dca-4c14-4e1d-9aec-0e0123ff4a39 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('summary_LV4_AI');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "summary_LV4_AI",
              "summary": "{\n  \"name\": \"summary_LV4_AI\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Citation Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\u0e18\\u0e19\\u0e32\\u0e04\\u0e32\\u0e23\\u0e41\\u0e2b\\u0e48\\u0e07\\u0e1b\\u0e23\\u0e30\\u0e40\\u0e17\\u0e28\\u0e44\\u0e17\\u0e22\\u0e01\\u0e33\\u0e2b\\u0e19\\u0e14\\u0e41\\u0e19\\u0e27\\u0e1b\\u0e0f\\u0e34\\u0e1a\\u0e31\\u0e15\\u0e34\\u0e2d\\u0e31\\u0e19\\u0e40\\u0e1b\\u0e47\\u0e19\\u0e21\\u0e32\\u0e15\\u0e23\\u0e10\\u0e32\\u0e19\\u0e02\\u0e31\\u0e49\\u0e19\\u0e15\\u0e33\\u0e2a\\u0e33\\u0e2b\\u0e23\\u0e31\\u0e1a\\u0e01\\u0e23\\u0e30\\u0e1a\\u0e27\\u0e19\\u0e01\\u0e32\\u0e23\\u0e23\\u0e31\\u0e1a\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19\\u0e19\\u0e34\\u0e15\\u0e34\\u0e1a\\u0e38\\u0e04\\u0e04\\u0e25 \\u0e40\\u0e1e\\u0e37\\u0e48\\u0e2d\\u0e43\\u0e2b\\u0e49\\u0e01\\u0e32\\u0e23\\u0e23\\u0e31\\u0e1a\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19\\u0e19\\u0e34\\u0e15\\u0e34\\u0e1a\\u0e38\\u0e04\\u0e04\\u0e25\\u0e21\\u0e35\\u0e04\\u0e27\\u0e32\\u0e21\\u0e23\\u0e31\\u0e14\\u0e01\\u0e38\\u0e21 \\u0e1b\\u0e25\\u0e2d\\u0e14\\u0e20\\u0e31\\u0e22 \\u0e41\\u0e25\\u0e30\\u0e16\\u0e39\\u0e01\\u0e15\\u0e49\\u0e2d\\u0e07\\u0e40\\u0e0a\\u0e37\\u0e48\\u0e2d\\u0e16\\u0e37\\u0e2d\\u0e44\\u0e14\\u0e49 \\u0e2d\\u0e31\\u0e19\\u0e08\\u0e30\\u0e0a\\u0e48\\u0e27\\u0e22\\u0e25\\u0e14\\u0e04\\u0e27\\u0e32\\u0e21\\u0e40\\u0e2a\\u0e35\\u0e48\\u0e22\\u0e07\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e43\\u0e2b\\u0e49\\u0e1a\\u0e23\\u0e34\\u0e01\\u0e32\\u0e23\\u0e02\\u0e2d\\u0e07\\u0e2a\\u0e16\\u0e32\\u0e1a\\u0e31\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e07\\u0e34\\u0e19 \\u0e41\\u0e25\\u0e30\\u0e40\\u0e2a\\u0e23\\u0e34\\u0e21\\u0e2a\\u0e23\\u0e49\\u0e32\\u0e07\\u0e04\\u0e27\\u0e32\\u0e21\\u0e40\\u0e0a\\u0e37\\u0e48\\u0e2d\\u0e21\\u0e31\\u0e48\\u0e19\\u0e41\\u0e01\\u0e48\\u0e1c\\u0e39\\u0e49\\u0e43\\u0e0a\\u0e49\\u0e1a\\u0e23\\u0e34\\u0e01\\u0e32\\u0e23 \\u0e42\\u0e14\\u0e22\\u0e21\\u0e35\\u0e2b\\u0e25\\u0e31\\u0e01\\u0e01\\u0e32\\u0e23\\u0e14\\u0e31\\u0e07\\u0e19\\u0e35\\u0e49:\\n1. \\u0e01\\u0e32\\u0e23\\u0e23\\u0e30\\u0e1a\\u0e38\\u0e15\\u0e31\\u0e27\\u0e15\\u0e19\\u0e41\\u0e25\\u0e30\\u0e1e\\u0e34\\u0e2a\\u0e39\\u0e08\\u0e19\\u0e4c\\u0e15\\u0e31\\u0e27\\u0e15\\u0e19\\u0e02\\u0e2d\\u0e07\\u0e1c\\u0e39\\u0e49\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19: \\u0e2a\\u0e16\\u0e32\\u0e1a\\u0e31\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e07\\u0e34\\u0e19\\u0e15\\u0e49\\u0e2d\\u0e07\\u0e01\\u0e33\\u0e2b\\u0e19\\u0e14\\u0e01\\u0e23\\u0e30\\u0e1a\\u0e27\\u0e19\\u0e01\\u0e32\\u0e23\\u0e17\\u0e35\\u0e48\\u0e21\\u0e35\\u0e04\\u0e27\\u0e32\\u0e21\\u0e23\\u0e31\\u0e14\\u0e01\\u0e38\\u0e21\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e23\\u0e30\\u0e1a\\u0e38\\u0e15\\u0e31\\u0e27\\u0e15\\u0e19 \\u0e41\\u0e25\\u0e30\\u0e15\\u0e23\\u0e27\\u0e08\\u0e2a\\u0e2d\\u0e1a\\u0e04\\u0e27\\u0e32\\u0e21\\u0e16\\u0e39\\u0e01\\u0e15\\u0e49\\u0e2d\\u0e07\\u0e02\\u0e2d\\u0e07\\u0e02\\u0e49\\u0e2d\\u0e21\\u0e39\\u0e25/\\u0e40\\u0e2d\\u0e01\\u0e2a\\u0e32\\u0e23\\u0e41\\u0e2a\\u0e14\\u0e07\\u0e15\\u0e19\\u0e02\\u0e2d\\u0e07\\u0e19\\u0e34\\u0e15\\u0e34\\u0e1a\\u0e38\\u0e04\\u0e04\\u0e25\\u0e1c\\u0e39\\u0e49\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19 \\u0e1c\\u0e39\\u0e49\\u0e21\\u0e35\\u0e2d\\u0e33\\u0e19\\u0e32\\u0e08\\u0e1c\\u0e39\\u0e01\\u0e1e\\u0e31\\u0e19\\u0e19\\u0e34\\u0e15\\u0e34\\u0e1a\\u0e38\\u0e04\\u0e04\\u0e25 \\u0e41\\u0e25\\u0e30\\u0e1c\\u0e39\\u0e49\\u0e01\\u0e23\\u0e30\\u0e17\\u0e33\\u0e01\\u0e32\\u0e23\\u0e41\\u0e17\\u0e19 \\u0e0b\\u0e36\\u0e48\\u0e07\\u0e15\\u0e49\\u0e2d\\u0e07\\u0e2a\\u0e2d\\u0e14\\u0e04\\u0e25\\u0e49\\u0e2d\\u0e07\\u0e01\\u0e31\\u0e1a\\u0e27\\u0e34\\u0e18\\u0e35\\u0e1b\\u0e0f\\u0e34\\u0e1a\\u0e31\\u0e15\\u0e34\\u0e43\\u0e19\\u0e1b\\u0e31\\u0e08\\u0e08\\u0e38\\u0e1a\\u0e31\\u0e19\\u0e17\\u0e35\\u0e48\\u0e2a\\u0e16\\u0e32\\u0e1a\\u0e31\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e07\\u0e34\\u0e19\\u0e43\\u0e0a\\u0e49\\u0e1e\\u0e34\\u0e2a\\u0e39\\u0e08\\u0e19\\u0e4c\\u0e15\\u0e31\\u0e27\\u0e15\\u0e19\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e17\\u0e33\\u0e18\\u0e38\\u0e23\\u0e01\\u0e23\\u0e23\\u0e21\\u0e17\\u0e32\\u0e07\\u0e01\\u0e32\\u0e23\\u0e40\\u0e07\\u0e34\\u0e19\\u0e01\\u0e31\\u0e1a\\u0e19\\u0e34\\u0e15\\u0e34\\u0e1a\\u0e38\\u0e04\\u0e04\\u0e25\\u0e14\\u0e49\\u0e27\\u0e22 \\u0e42\\u0e14\\u0e22\\u0e40\\u0e2d\\u0e01\\u0e2a\\u0e32\\u0e23\\u0e1b\\u0e23\\u0e30\\u0e01\\u0e2d\\u0e1a\\u0e01\\u0e32\\u0e23\\u0e23\\u0e31\\u0e1a\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19\\u0e19\\u0e34\\u0e15\\u0e34\\u0e1a\\u0e38\\u0e04\\u0e04\\u0e25 \\u0e04\\u0e27\\u0e23\\u0e1b\\u0e23\\u0e30\\u0e01\\u0e2d\\u0e1a\\u0e14\\u0e49\\u0e27\\u0e22\\u0e2b\\u0e25\\u0e31\\u0e01\\u0e10\\u0e32\\u0e19\\u0e14\\u0e31\\u0e07\\u0e15\\u0e48\\u0e2d\\u0e44\\u0e1b\\u0e19\\u0e35\\u0e49:\\n    1.1 \\u0e43\\u0e1a\\u0e04\\u0e33\\u0e23\\u0e49\\u0e2d\\u0e07 \\u0e02\\u0e49\\u0e2d\\u0e15\\u0e01\\u0e25\\u0e07\\u0e41\\u0e25\\u0e30\\u0e40\\u0e07\\u0e37\\u0e48\\u0e2d\\u0e19\\u0e44\\u0e02\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e43\\u0e0a\\u0e49\\u0e1a\\u0e23\\u0e34\\u0e01\\u0e32\\u0e23 \\u0e23\\u0e27\\u0e21\\u0e16\\u0e36\\u0e07\\u0e04\\u0e33\\u0e22\\u0e34\\u0e19\\u0e22\\u0e2d\\u0e21\\u0e43\\u0e2b\\u0e49\\u0e40\\u0e1b\\u0e34\\u0e14\\u0e40\\u0e1c\\u0e22\\u0e02\\u0e49\\u0e2d\\u0e21\\u0e39\\u0e25 \\u0e0b\\u0e36\\u0e48\\u0e07\\u0e25\\u0e07\\u0e19\\u0e32\\u0e21\\u0e42\\u0e14\\u0e22\\u0e1c\\u0e39\\u0e49\\u0e21\\u0e35\\u0e2d\\u0e33\\u0e19\\u0e32\\u0e08\\u0e25\\u0e07\\u0e19\\u0e32\\u0e21\\u0e1c\\u0e39\\u0e01\\u0e1e\\u0e31\\u0e19\\u0e19\\u0e34\\u0e15\\u0e34\\u0e1a\\u0e38\\u0e04\\u0e04\\u0e25\\n    1.2 \\u0e40\\u0e2d\\u0e01\\u0e2a\\u0e32\\u0e23\\u0e2b\\u0e23\\u0e37\\u0e2d\\u0e2b\\u0e25\\u0e31\\u0e01\\u0e10\\u0e32\\u0e19\\u0e17\\u0e35\\u0e48\\u0e41\\u0e2a\\u0e14\\u0e07\\u0e27\\u0e48\\u0e32\\u0e1a\\u0e31\\u0e0d\\u0e0a\\u0e35\\u0e40\\u0e07\\u0e34\\u0e19\\u0e1d\\u0e32\\u0e01\\u0e2d\\u0e2d\\u0e21\\u0e17\\u0e23\\u0e31\\u0e1e\\u0e22\\u0e4c\\u0e2b\\u0e23\\u0e37\\u0e2d\\u0e01\\u0e23\\u0e30\\u0e41\\u0e2a\\u0e23\\u0e32\\u0e22\\u0e27\\u0e31\\u0e19\\u0e17\\u0e35\\u0e48\\u0e1b\\u0e23\\u0e30\\u0e2a\\u0e07\\u0e04\\u0e4c\\u0e08\\u0e30\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19 \\u0e21\\u0e35\\u0e19\\u0e34\\u0e15\\u0e34\\u0e1a\\u0e38\\u0e04\\u0e04\\u0e25\\u0e1c\\u0e39\\u0e49\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19\\u0e40\\u0e1b\\u0e47\\u0e19\\u0e40\\u0e08\\u0e49\\u0e32\\u0e02\\u0e2d\\u0e07\\u0e1a\\u0e31\\u0e0d\\u0e0a\\u0e35\\n    1.3 \\u0e1a\\u0e31\\u0e15\\u0e23\\u0e1b\\u0e23\\u0e30\\u0e0a\\u0e32\\u0e0a\\u0e19 \\u0e2b\\u0e23\\u0e37\\u0e2d\\u0e2b\\u0e19\\u0e31\\u0e07\\u0e2a\\u0e37\\u0e2d\\u0e40\\u0e14\\u0e34\\u0e19\\u0e17\\u0e32\\u0e07 (\\u0e2b\\u0e23\\u0e37\\u0e2d\\u0e2a\\u0e33\\u0e40\\u0e19\\u0e32) \\u0e02\\u0e2d\\u0e07\\u0e1c\\u0e39\\u0e49\\u0e21\\u0e35\\u0e2d\\u0e33\\u0e19\\u0e32\\u0e08\\u0e25\\u0e07\\u0e19\\u0e32\\u0e21\\u0e41\\u0e17\\u0e19\\u0e19\\u0e34\\u0e15\\u0e34\\u0e1a\\u0e38\\u0e04\\u0e04\\u0e25 \\u0e2b\\u0e23\\u0e37\\u0e2d\\u0e1c\\u0e39\\u0e49\\u0e17\\u0e35\\u0e48\\u0e40\\u0e01\\u0e35\\u0e48\\u0e22\\u0e27\\u0e02\\u0e49\\u0e2d\\u0e07\\u0e2a\\u0e33\\u0e2b\\u0e23\\u0e31\\u0e1a\\u0e01\\u0e23\\u0e13\\u0e35\\u0e1a\\u0e38\\u0e04\\u0e04\\u0e25\\u0e17\\u0e35\\u0e48\\u0e21\\u0e35\\u0e01\\u0e32\\u0e23\\u0e15\\u0e01\\u0e25\\u0e07\\u0e01\\u0e31\\u0e19\\u0e17\\u0e32\\u0e07\\u0e01\\u0e0e\\u0e2b\\u0e21\\u0e32\\u0e22 \\u0e17\\u0e35\\u0e48\\u0e44\\u0e14\\u0e49\\u0e23\\u0e31\\u0e1a\\u0e21\\u0e2d\\u0e1a\\u0e2b\\u0e21\\u0e32\\u0e22\\u0e2b\\u0e23\\u0e37\\u0e2d\\u0e44\\u0e14\\u0e49\\u0e23\\u0e31\\u0e1a\\u0e21\\u0e2d\\u0e1a\\u0e2d\\u0e33\\u0e19\\u0e32\\u0e08\\u0e43\\u0e2b\\u0e49\\u0e2a\\u0e23\\u0e49\\u0e32\\u0e07\\u0e04\\u0e27\\u0e32\\u0e21\\u0e2a\\u0e31\\u0e21\\u0e1e\\u0e31\\u0e19\\u0e18\\u0e4c\\u0e17\\u0e32\\u0e07\\u0e18\\u0e38\\u0e23\\u0e01\\u0e34\\u0e08 \\u0e40\\u0e0a\\u0e48\\u0e19 \\u0e01\\u0e23\\u0e23\\u0e21\\u0e01\\u0e32\\u0e23\\u0e1c\\u0e39\\u0e49\\u0e21\\u0e35\\u0e2d\\u0e33\\u0e19\\u0e32\\u0e08\\u0e25\\u0e07\\u0e19\\u0e32\\u0e21 \\u0e1c\\u0e39\\u0e49\\u0e21\\u0e35\\u0e2d\\u0e33\\u0e19\\u0e32\\u0e08\\u0e25\\u0e07\\u0e19\\u0e32\\u0e21\\u0e1c\\u0e39\\u0e01\\u0e1e\\u0e31\\u0e19\\u0e19\\u0e34\\u0e15\\u0e34\\u0e1a\\u0e38\\u0e04\\u0e04\\u0e25 \\u0e1c\\u0e39\\u0e49\\u0e21\\u0e35\\u0e2d\\u0e33\\u0e19\\u0e32\\u0e08\\u0e2a\\u0e39\\u0e07\\u0e2a\\u0e38\\u0e14\\u0e02\\u0e2d\\u0e07\\u0e2b\\u0e19\\u0e48\\u0e27\\u0e22\\u0e07\\u0e32\\u0e19\\u0e01\\u0e23\\u0e13\\u0e35\\u0e40\\u0e1b\\u0e47\\u0e19\\u0e2b\\u0e19\\u0e48\\u0e27\\u0e22\\u0e07\\u0e32\\u0e19\\u0e02\\u0e2d\\u0e07\\u0e23\\u0e31\\u0e10 (\\u0e1e\\u0e23\\u0e49\\u0e2d\\u0e21\\u0e41\\u0e19\\u0e1a\\u0e2b\\u0e19\\u0e31\\u0e07\\u0e2a\\u0e37\\u0e2d\\u0e41\\u0e15\\u0e48\\u0e07\\u0e15\\u0e31\\u0e49\\u0e07\\u0e2f\\u0e46) \\u0e41\\u0e25\\u0e30\\u0e1c\\u0e39\\u0e49\\u0e23\\u0e31\\u0e1a\\u0e21\\u0e2d\\u0e1a\\u0e2d\\u0e33\\u0e19\\u0e32\\u0e08\\n    1.4 \\u0e2b\\u0e19\\u0e31\\u0e07\\u0e2a\\u0e37\\u0e2d\\u0e23\\u0e31\\u0e1a\\u0e23\\u0e2d\\u0e07\\u0e01\\u0e32\\u0e23\\u0e08\\u0e14\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19\\u0e19\\u0e34\\u0e15\\u0e34\\u0e1a\\u0e38\\u0e04\\u0e04\\u0e25 \\u0e17\\u0e35\\u0e48\\u0e19\\u0e32\\u0e22\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19\\u0e2d\\u0e2d\\u0e01\\u0e43\\u0e2b\\u0e49\\u0e44\\u0e21\\u0e48\\u0e40\\u0e01\\u0e34\\u0e19 3 \\u0e40\\u0e14\\u0e37\\u0e2d\\u0e19 \\u0e2b\\u0e23\\u0e37\\u0e2d\\u0e40\\u0e2d\\u0e01\\u0e2a\\u0e32\\u0e23\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e08\\u0e31\\u0e14\\u0e15\\u0e31\\u0e49\\u0e07\\u0e19\\u0e34\\u0e15\\u0e34\\u0e1a\\u0e38\\u0e04\\u0e04\\u0e25\\u0e15\\u0e32\\u0e21\\u0e17\\u0e35\\u0e48\\u0e2a\\u0e16\\u0e32\\u0e1a\\u0e31\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e07\\u0e34\\u0e19\\u0e01\\u0e33\\u0e2b\\u0e19\\u0e14\\n    1.5 \\u0e1a\\u0e31\\u0e15\\u0e23\\u0e1b\\u0e23\\u0e30\\u0e08\\u0e33\\u0e15\\u0e31\\u0e27\\u0e1c\\u0e39\\u0e49\\u0e40\\u0e2a\\u0e35\\u0e22\\u0e20\\u0e32\\u0e29\\u0e35\\u0e2d\\u0e32\\u0e01\\u0e23 (\\u0e16\\u0e49\\u0e32\\u0e21\\u0e35)\\n    1.6 \\u0e2b\\u0e19\\u0e31\\u0e07\\u0e2a\\u0e37\\u0e2d\\u0e21\\u0e2d\\u0e1a\\u0e2d\\u0e33\\u0e19\\u0e32\\u0e08 (\\u0e16\\u0e49\\u0e32\\u0e21\\u0e35) \\u0e01\\u0e23\\u0e13\\u0e35\\u0e1c\\u0e39\\u0e49\\u0e21\\u0e35\\u0e2d\\u0e33\\u0e19\\u0e32\\u0e08\\u0e25\\u0e07\\u0e19\\u0e32\\u0e21\\u0e1c\\u0e39\\u0e01\\u0e1e\\u0e31\\u0e19\\u0e19\\u0e34\\u0e15\\u0e34\\u0e1a\\u0e38\\u0e04\\u0e04\\u0e25 \\u0e1c\\u0e39\\u0e49\\u0e21\\u0e35\\u0e2d\\u0e33\\u0e19\\u0e32\\u0e08\\u0e2a\\u0e39\\u0e07\\u0e2a\\u0e38\\u0e14\\u0e02\\u0e2d\\u0e07\\u0e2b\\u0e19\\u0e48\\u0e27\\u0e22\\u0e07\\u0e32\\u0e19\\u0e01\\u0e23\\u0e13\\u0e35\\u0e40\\u0e1b\\u0e47\\u0e19\\u0e2b\\u0e19\\u0e48\\u0e27\\u0e22\\u0e07\\u0e32\\u0e19\\u0e02\\u0e2d\\u0e07\\u0e23\\u0e31\\u0e10 \\u0e44\\u0e21\\u0e48\\u0e2a\\u0e32\\u0e21\\u0e32\\u0e23\\u0e16\\u0e14\\u0e33\\u0e40\\u0e19\\u0e34\\u0e19\\u0e01\\u0e32\\u0e23\\u0e14\\u0e49\\u0e27\\u0e22\\u0e15\\u0e19\\u0e40\\u0e2d\\u0e07 \\u0e17\\u0e31\\u0e49\\u0e07\\u0e19\\u0e35\\u0e49 \\u0e02\\u0e36\\u0e49\\u0e19\\u0e01\\u0e31\\u0e1a\\u0e19\\u0e42\\u0e22\\u0e1a\\u0e32\\u0e22\\u0e01\\u0e32\\u0e23\\u0e2d\\u0e19\\u0e38\\u0e0d\\u0e32\\u0e15\\u0e43\\u0e2b\\u0e49\\u0e21\\u0e35\\u0e1c\\u0e39\\u0e49\\u0e23\\u0e31\\u0e1a\\u0e21\\u0e2d\\u0e1a\\u0e2d\\u0e33\\u0e19\\u0e32\\u0e08\\u0e14\\u0e33\\u0e40\\u0e19\\u0e34\\u0e19\\u0e01\\u0e32\\u0e23\\u0e41\\u0e17\\u0e19\\u0e02\\u0e2d\\u0e07\\u0e2a\\u0e16\\u0e32\\u0e1a\\u0e31\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e07\\u0e34\\u0e19\\n    1.7 \\u0e2a\\u0e16\\u0e32\\u0e1a\\u0e31\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e07\\u0e34\\u0e19\\u0e2d\\u0e32\\u0e08\\u0e01\\u0e33\\u0e2b\\u0e19\\u0e14\\u0e2b\\u0e25\\u0e31\\u0e01\\u0e10\\u0e32\\u0e19\\u0e2d\\u0e37\\u0e48\\u0e19\\u0e40\\u0e1e\\u0e34\\u0e48\\u0e21\\u0e40\\u0e15\\u0e34\\u0e21\\u0e15\\u0e32\\u0e21\\u0e04\\u0e27\\u0e32\\u0e21\\u0e08\\u0e33\\u0e40\\u0e1b\\u0e47\\u0e19\\n2. \\u0e01\\u0e32\\u0e23\\u0e15\\u0e23\\u0e27\\u0e08\\u0e2a\\u0e2d\\u0e1a\\u0e04\\u0e27\\u0e32\\u0e21\\u0e16\\u0e39\\u0e01\\u0e15\\u0e49\\u0e2d\\u0e07\\u0e40\\u0e0a\\u0e37\\u0e48\\u0e2d\\u0e16\\u0e37\\u0e2d\\u0e44\\u0e14\\u0e49\\u0e02\\u0e2d\\u0e07\\u0e2b\\u0e21\\u0e32\\u0e22\\u0e40\\u0e25\\u0e02\\u0e2d\\u0e49\\u0e32\\u0e07\\u0e2d\\u0e34\\u0e07 (Tax ID) \\u0e17\\u0e35\\u0e48\\u0e43\\u0e0a\\u0e49\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19: \\u0e2a\\u0e16\\u0e32\\u0e1a\\u0e31\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e07\\u0e34\\u0e19\\u0e15\\u0e49\\u0e2d\\u0e07\\u0e15\\u0e23\\u0e27\\u0e08\\u0e2a\\u0e2d\\u0e1a\\u0e04\\u0e27\\u0e32\\u0e21\\u0e16\\u0e39\\u0e01\\u0e15\\u0e49\\u0e2d\\u0e07\\u0e02\\u0e2d\\u0e07\\u0e40\\u0e25\\u0e02\\u0e1b\\u0e23\\u0e30\\u0e08\\u0e33\\u0e15\\u0e31\\u0e27\\u0e1c\\u0e39\\u0e49\\u0e40\\u0e2a\\u0e35\\u0e22\\u0e20\\u0e32\\u0e29\\u0e35\\u0e2d\\u0e32\\u0e01\\u0e23\\u0e17\\u0e35\\u0e48\\u0e43\\u0e0a\\u0e49\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19 \\u0e15\\u0e32\\u0e21\\u0e40\\u0e01\\u0e13\\u0e11\\u0e4c\\u0e01\\u0e32\\u0e23\\u0e1a\\u0e23\\u0e34\\u0e2b\\u0e32\\u0e23\\u0e04\\u0e27\\u0e32\\u0e21\\u0e40\\u0e2a\\u0e35\\u0e48\\u0e22\\u0e07\\u0e02\\u0e2d\\u0e07\\u0e2a\\u0e16\\u0e32\\u0e1a\\u0e31\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e07\\u0e34\\u0e19\\n3. \\u0e01\\u0e32\\u0e23\\u0e04\\u0e27\\u0e1a\\u0e04\\u0e38\\u0e21\\u0e04\\u0e27\\u0e32\\u0e21\\u0e40\\u0e2a\\u0e35\\u0e48\\u0e22\\u0e07\\u0e02\\u0e2d\\u0e07\\u0e01\\u0e23\\u0e30\\u0e1a\\u0e27\\u0e19\\u0e01\\u0e32\\u0e23\\u0e1b\\u0e0f\\u0e34\\u0e1a\\u0e31\\u0e15\\u0e34\\u0e07\\u0e32\\u0e19\\u0e17\\u0e35\\u0e48\\u0e40\\u0e01\\u0e35\\u0e48\\u0e22\\u0e27\\u0e02\\u0e49\\u0e2d\\u0e07:\\n    3.1 \\u0e01\\u0e48\\u0e2d\\u0e19\\u0e23\\u0e31\\u0e1a\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19\\u0e17\\u0e38\\u0e01\\u0e04\\u0e23\\u0e31\\u0e49\\u0e07 \\u0e2a\\u0e16\\u0e32\\u0e1a\\u0e31\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e07\\u0e34\\u0e19\\u0e15\\u0e49\\u0e2d\\u0e07\\u0e41\\u0e2a\\u0e14\\u0e07\\u0e40\\u0e07\\u0e37\\u0e48\\u0e2d\\u0e19\\u0e44\\u0e02\\u0e01\\u0e32\\u0e23\\u0e43\\u0e0a\\u0e49\\u0e1a\\u0e23\\u0e34\\u0e01\\u0e32\\u0e23 (Terms and Conditions) \\u0e41\\u0e25\\u0e30\\u0e02\\u0e2d\\u0e04\\u0e33\\u0e22\\u0e34\\u0e19\\u0e22\\u0e2d\\u0e21\\u0e08\\u0e32\\u0e01\\u0e1c\\u0e39\\u0e49\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e1b\\u0e34\\u0e14\\u0e40\\u0e1c\\u0e22\\u0e02\\u0e49\\u0e2d\\u0e21\\u0e39\\u0e25\\u0e17\\u0e35\\u0e48\\u0e40\\u0e01\\u0e35\\u0e48\\u0e22\\u0e27\\u0e02\\u0e49\\u0e2d\\u0e07 (Consent) \\u0e40\\u0e1e\\u0e37\\u0e48\\u0e2d\\u0e43\\u0e2b\\u0e49\\u0e1c\\u0e39\\u0e49\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19\\u0e23\\u0e31\\u0e1a\\u0e17\\u0e23\\u0e32\\u0e1a\\u0e02\\u0e49\\u0e2d\\u0e21\\u0e39\\u0e25\\u0e2d\\u0e22\\u0e48\\u0e32\\u0e07\\u0e04\\u0e23\\u0e1a\\u0e16\\u0e49\\u0e27\\u0e19 \\u0e16\\u0e39\\u0e01\\u0e15\\u0e49\\u0e2d\\u0e07 \\u0e41\\u0e25\\u0e30\\u0e0a\\u0e31\\u0e14\\u0e40\\u0e08\\u0e19 \\u0e15\\u0e25\\u0e2d\\u0e14\\u0e08\\u0e19\\u0e21\\u0e35\\u0e2b\\u0e25\\u0e31\\u0e01\\u0e10\\u0e32\\u0e19\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e43\\u0e2b\\u0e49\\u0e04\\u0e27\\u0e32\\u0e21\\u0e22\\u0e34\\u0e19\\u0e22\\u0e2d\\u0e21\\u0e41\\u0e01\\u0e48\\u0e2a\\u0e16\\u0e32\\u0e1a\\u0e31\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e07\\u0e34\\u0e19\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e1b\\u0e34\\u0e14\\u0e40\\u0e1c\\u0e22\\u0e02\\u0e49\\u0e2d\\u0e21\\u0e39\\u0e25\\u0e02\\u0e2d\\u0e07\\u0e15\\u0e19\\n    3.2 \\u0e43\\u0e2b\\u0e49\\u0e2a\\u0e16\\u0e32\\u0e1a\\u0e31\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e07\\u0e34\\u0e19\\u0e41\\u0e08\\u0e49\\u0e07\\u0e1c\\u0e25\\u0e01\\u0e32\\u0e23\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19\\u0e43\\u0e2b\\u0e49\\u0e1c\\u0e39\\u0e49\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19\\u0e17\\u0e23\\u0e32\\u0e1a\\u0e40\\u0e1b\\u0e47\\u0e19\\u0e25\\u0e32\\u0e22\\u0e25\\u0e31\\u0e01\\u0e29\\u0e13\\u0e4c\\u0e2d\\u0e31\\u0e01\\u0e29\\u0e23 \\u0e43\\u0e19\\u0e23\\u0e39\\u0e1b\\u0e41\\u0e1a\\u0e1a\\u0e40\\u0e2d\\u0e01\\u0e2a\\u0e32\\u0e23\\u0e2b\\u0e23\\u0e37\\u0e2d\\u0e2d\\u0e34\\u0e40\\u0e25\\u0e47\\u0e01\\u0e17\\u0e23\\u0e2d\\u0e19\\u0e34\\u0e01\\u0e2a\\u0e4c \\u0e17\\u0e31\\u0e49\\u0e07\\u0e01\\u0e23\\u0e13\\u0e35\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19\\u0e2a\\u0e33\\u0e40\\u0e23\\u0e47\\u0e08\\u0e41\\u0e25\\u0e30\\u0e44\\u0e21\\u0e48\\u0e2a\\u0e33\\u0e40\\u0e23\\u0e47\\u0e08\\n    3.3 \\u0e43\\u0e19\\u0e01\\u0e23\\u0e13\\u0e35\\u0e1c\\u0e39\\u0e49\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19\\u0e21\\u0e35\\u0e04\\u0e27\\u0e32\\u0e21\\u0e1b\\u0e23\\u0e30\\u0e2a\\u0e07\\u0e04\\u0e4c\\u0e17\\u0e35\\u0e48\\u0e08\\u0e30\\u0e02\\u0e2d\\u0e40\\u0e1b\\u0e25\\u0e35\\u0e48\\u0e22\\u0e19\\u0e41\\u0e1b\\u0e25\\u0e07 \\u0e41\\u0e01\\u0e49\\u0e44\\u0e02 \\u0e2b\\u0e23\\u0e37\\u0e2d\\u0e22\\u0e01\\u0e40\\u0e25\\u0e34\\u0e01\\u0e01\\u0e32\\u0e23\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19 \\u0e43\\u0e2b\\u0e49\\u0e2a\\u0e16\\u0e32\\u0e1a\\u0e31\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e07\\u0e34\\u0e19\\u0e1e\\u0e34\\u0e2a\\u0e39\\u0e08\\u0e19\\u0e4c\\u0e15\\u0e31\\u0e27\\u0e15\\u0e19\\u0e02\\u0e2d\\u0e07\\u0e1c\\u0e39\\u0e49\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19\\u0e14\\u0e49\\u0e27\\u0e22\\u0e04\\u0e27\\u0e32\\u0e21\\u0e23\\u0e31\\u0e14\\u0e01\\u0e38\\u0e21 \\u0e2a\\u0e2d\\u0e14\\u0e04\\u0e25\\u0e49\\u0e2d\\u0e07\\u0e01\\u0e31\\u0e1a\\u0e27\\u0e34\\u0e18\\u0e35\\u0e1b\\u0e0f\\u0e34\\u0e1a\\u0e31\\u0e15\\u0e34\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e1e\\u0e34\\u0e2a\\u0e39\\u0e08\\u0e19\\u0e4c\\u0e15\\u0e31\\u0e27\\u0e15\\u0e19\\u0e43\\u0e19\\u0e02\\u0e31\\u0e49\\u0e19\\u0e15\\u0e2d\\u0e19\\u0e02\\u0e2d\\u0e07\\u0e01\\u0e32\\u0e23\\u0e23\\u0e31\\u0e1a\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19\\u0e14\\u0e49\\u0e27\\u0e22\\n    3.4 \\u0e43\\u0e2b\\u0e49\\u0e2a\\u0e16\\u0e32\\u0e1a\\u0e31\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e07\\u0e34\\u0e19\\u0e43\\u0e2b\\u0e49\\u0e02\\u0e49\\u0e2d\\u0e21\\u0e39\\u0e25\\u0e41\\u0e25\\u0e30\\u0e41\\u0e19\\u0e30\\u0e19\\u0e33\\u0e25\\u0e39\\u0e01\\u0e04\\u0e49\\u0e32\\u0e19\\u0e34\\u0e15\\u0e34\\u0e1a\\u0e38\\u0e04\\u0e04\\u0e25\\u0e43\\u0e2b\\u0e49\\u0e21\\u0e35\\u0e01\\u0e23\\u0e30\\u0e1a\\u0e27\\u0e19\\u0e01\\u0e32\\u0e23\\u0e04\\u0e27\\u0e1a\\u0e04\\u0e38\\u0e21\\u0e20\\u0e32\\u0e22\\u0e43\\u0e19\\u0e17\\u0e35\\u0e48\\u0e14\\u0e35\\u0e43\\u0e19\\u0e40\\u0e23\\u0e37\\u0e48\\u0e2d\\u0e07\\u0e01\\u0e32\\u0e23\\u0e43\\u0e0a\\u0e49\\u0e1a\\u0e23\\u0e34\\u0e01\\u0e32\\u0e23\\u0e1e\\u0e23\\u0e49\\u0e2d\\u0e21\\u0e40\\u0e1e\\u0e22\\u0e4c \\u0e19\\u0e2d\\u0e01\\u0e08\\u0e32\\u0e01\\u0e19\\u0e35\\u0e49 \\u0e43\\u0e2b\\u0e49\\u0e2a\\u0e16\\u0e32\\u0e1a\\u0e31\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e07\\u0e34\\u0e19\\u0e40\\u0e15\\u0e23\\u0e35\\u0e22\\u0e21\\u0e04\\u0e27\\u0e32\\u0e21\\u0e1e\\u0e23\\u0e49\\u0e2d\\u0e21\\u0e40\\u0e08\\u0e49\\u0e32\\u0e2b\\u0e19\\u0e49\\u0e32\\u0e17\\u0e35\\u0e48\\u0e2a\\u0e32\\u0e02\\u0e32 \\u0e41\\u0e25\\u0e30 Call Center \\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e2a\\u0e37\\u0e48\\u0e2d\\u0e2a\\u0e32\\u0e23\\u0e41\\u0e25\\u0e30\\u0e15\\u0e2d\\u0e1a\\u0e02\\u0e49\\u0e2d\\u0e0b\\u0e31\\u0e01\\u0e16\\u0e32\\u0e21\\u0e25\\u0e39\\u0e01\\u0e04\\u0e49\\u0e32\\u0e19\\u0e34\\u0e15\\u0e34\\u0e1a\\u0e38\\u0e04\\u0e04\\u0e25\\u0e14\\u0e49\\u0e27\\u0e22\\n\\u0e17\\u0e31\\u0e49\\u0e07\\u0e19\\u0e35\\u0e49 \\u0e2b\\u0e19\\u0e48\\u0e27\\u0e22\\u0e07\\u0e32\\u0e19\\u0e14\\u0e49\\u0e32\\u0e19\\u0e01\\u0e32\\u0e23\\u0e01\\u0e33\\u0e01\\u0e31\\u0e1a\\u0e01\\u0e32\\u0e23\\u0e1b\\u0e0f\\u0e34\\u0e1a\\u0e31\\u0e15\\u0e34\\u0e07\\u0e32\\u0e19\\u0e41\\u0e25\\u0e30\\u0e14\\u0e49\\u0e32\\u0e19\\u0e01\\u0e32\\u0e23\\u0e15\\u0e23\\u0e27\\u0e08\\u0e2a\\u0e2d\\u0e1a\\u0e20\\u0e32\\u0e22\\u0e43\\u0e19\\u0e02\\u0e2d\\u0e07\\u0e2a\\u0e16\\u0e32\\u0e1a\\u0e31\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e07\\u0e34\\u0e19 \\u0e15\\u0e49\\u0e2d\\u0e07\\u0e21\\u0e35\\u0e2a\\u0e48\\u0e27\\u0e19\\u0e23\\u0e48\\u0e27\\u0e21\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e01\\u0e33\\u0e01\\u0e31\\u0e1a\\u0e14\\u0e39\\u0e41\\u0e25\\u0e41\\u0e25\\u0e30\\u0e2a\\u0e2d\\u0e1a\\u0e17\\u0e32\\u0e19\\u0e01\\u0e32\\u0e23\\u0e1b\\u0e0f\\u0e34\\u0e1a\\u0e31\\u0e15\\u0e34\\u0e07\\u0e32\\u0e19 \\u0e43\\u0e19\\u0e01\\u0e23\\u0e30\\u0e1a\\u0e27\\u0e19\\u0e01\\u0e32\\u0e23\\u0e23\\u0e31\\u0e1a\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19\\u0e02\\u0e2d\\u0e07\\u0e2a\\u0e16\\u0e32\\u0e1a\\u0e31\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e07\\u0e34\\u0e19 \\u0e43\\u0e2b\\u0e49\\u0e40\\u0e1b\\u0e47\\u0e19\\u0e44\\u0e1b\\u0e15\\u0e32\\u0e21\\u0e21\\u0e32\\u0e15\\u0e23\\u0e10\\u0e32\\u0e19\\u0e02\\u0e31\\u0e49\\u0e19\\u0e15\\u0e33\\u0e17\\u0e35\\u0e48\\u0e18\\u0e19\\u0e32\\u0e04\\u0e32\\u0e23\\u0e41\\u0e2b\\u0e48\\u0e07\\u0e1b\\u0e23\\u0e30\\u0e40\\u0e17\\u0e28\\u0e44\\u0e17\\u0e22\\u0e01\\u0e33\\u0e2b\\u0e19\\u0e14 \\u0e2d\\u0e22\\u0e48\\u0e32\\u0e07\\u0e2a\\u0e21\\u0e48\\u0e33\\u0e40\\u0e2a\\u0e21\\u0e2d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Citation Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\u0e44\\u0e21\\u0e48\\u0e23\\u0e30\\u0e1a\\u0e38\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Law/Regulation Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\u0e17\\u0e35\\u0e48 \\u0e18\\u0e39\\u0e1b\\u0e17.\\u0e1d\\u0e15\\u0e17.\\u0e27. /! /2560 \\u0e40\\u0e23\\u0e37\\u0e48\\u0e2d\\u0e07 \\u0e41\\u0e19\\u0e27\\u0e1b\\u0e0f\\u0e34\\u0e1a\\u0e31\\u0e15\\u0e34\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e23\\u0e31\\u0e1a\\u0e25\\u0e07\\u0e17\\u0e30\\u0e40\\u0e1a\\u0e35\\u0e22\\u0e19\\u0e1e\\u0e23\\u0e49\\u0e2d\\u0e21\\u0e40\\u0e1e\\u0e22\\u0e4c\\u0e2a\\u0e33\\u0e2b\\u0e23\\u0e31\\u0e1a\\u0e19\\u0e34\\u0e15\\u0e34\\u0e1a\\u0e38\\u0e04\\u0e04\\u0e25\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0e27\\u0e31\\u0e19\\u0e17\\u0e35\\u0e48\\u0e01\\u0e0e\\u0e2b\\u0e21\\u0e32\\u0e22/\\u0e01\\u0e0e\\u0e40\\u0e01\\u0e13\\u0e11\\u0e4c\\u0e01\\u0e33\\u0e2b\\u0e19\\u0e14\\u0e43\\u0e2b\\u0e49\\u0e14\\u0e33\\u0e40\\u0e19\\u0e34\\u0e19\\u0e01\\u0e32\\u0e23\\u0e41\\u0e25\\u0e49\\u0e27\\u0e40\\u0e2a\\u0e23\\u0e47\\u0e08\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\u0e44\\u0e21\\u0e48\\u0e1e\\u0e1a\\u0e02\\u0e49\\u0e2d\\u0e21\\u0e39\\u0e25\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0e2a\\u0e34\\u0e48\\u0e07\\u0e17\\u0e35\\u0e48 Risk Owner \\u0e15\\u0e49\\u0e2d\\u0e07\\u0e14\\u0e33\\u0e40\\u0e19\\u0e34\\u0e19\\u0e01\\u0e32\\u0e23\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\u0e1b\\u0e23\\u0e30\\u0e40\\u0e21\\u0e34\\u0e19 Gap Analysis \\u0e41\\u0e25\\u0e30\\u0e08\\u0e31\\u0e14\\u0e17\\u0e33 Action Plan (\\u0e16\\u0e49\\u0e32\\u0e21\\u0e35)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0e42\\u0e17\\u0e29/\\u0e1c\\u0e25\\u0e01\\u0e23\\u0e30\\u0e17\\u0e1a\\u0e01\\u0e23\\u0e13\\u0e35\\u0e44\\u0e21\\u0e48\\u0e1b\\u0e0f\\u0e34\\u0e1a\\u0e31\\u0e15\\u0e34\\u0e15\\u0e32\\u0e21\\u0e01\\u0e0e\\u0e2b\\u0e21\\u0e32\\u0e22/\\u0e01\\u0e0e\\u0e40\\u0e01\\u0e13\\u0e11\\u0e4c\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\u0e2d\\u0e37\\u0e48\\u0e19\\u0e46\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0e42\\u0e17\\u0e29\\u0e08\\u0e33\\u0e04\\u0e38\\u0e01\\u0e2a\\u0e39\\u0e07\\u0e2a\\u0e38\\u0e14 (\\u0e40\\u0e21\\u0e37\\u0e48\\u0e2d\\u0e40\\u0e25\\u0e37\\u0e2d\\u0e01\\u0e42\\u0e17\\u0e29/\\u0e1c\\u0e25\\u0e01\\u0e23\\u0e30\\u0e17\\u0e1a\\u0e01\\u0e23\\u0e13\\u0e35\\u0e44\\u0e21\\u0e48\\u0e1b\\u0e0f\\u0e34\\u0e1a\\u0e31\\u0e15\\u0e34\\u0e15\\u0e32\\u0e21\\u0e01\\u0e0e\\u0e2b\\u0e21\\u0e32\\u0e22/\\u0e01\\u0e0e\\u0e40\\u0e01\\u0e13\\u0e11\\u0e4c \\u0e40\\u0e1b\\u0e47\\u0e19 \\\"\\u0e42\\u0e17\\u0e29\\u0e2d\\u0e32\\u0e0d\\u0e32/\\u0e08\\u0e33\\u0e04\\u0e38\\u0e01 \\\")\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\u0e44\\u0e21\\u0e48\\u0e23\\u0e30\\u0e1a\\u0e38\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0e42\\u0e17\\u0e29\\u0e1b\\u0e23\\u0e31\\u0e1a\\u0e23\\u0e32\\u0e22\\u0e27\\u0e31\\u0e19 (\\u0e40\\u0e21\\u0e37\\u0e48\\u0e2d\\u0e40\\u0e25\\u0e37\\u0e2d\\u0e01\\u0e42\\u0e17\\u0e29/\\u0e1c\\u0e25\\u0e01\\u0e23\\u0e30\\u0e17\\u0e1a\\u0e01\\u0e23\\u0e13\\u0e35\\u0e44\\u0e21\\u0e48\\u0e1b\\u0e0f\\u0e34\\u0e1a\\u0e31\\u0e15\\u0e34\\u0e15\\u0e32\\u0e21\\u0e01\\u0e0e\\u0e2b\\u0e21\\u0e32\\u0e22/\\u0e01\\u0e0e\\u0e40\\u0e01\\u0e13\\u0e11\\u0e4c \\u0e40\\u0e1b\\u0e47\\u0e19 \\\"\\u0e42\\u0e17\\u0e29\\u0e1b\\u0e23\\u0e31\\u0e1a\\\")\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\u0e44\\u0e21\\u0e48\\u0e23\\u0e30\\u0e1a\\u0e38\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0e42\\u0e17\\u0e29\\u0e1b\\u0e23\\u0e31\\u0e1a\\u0e2a\\u0e39\\u0e07\\u0e2a\\u0e38\\u0e14 (\\u0e40\\u0e21\\u0e37\\u0e48\\u0e2d\\u0e40\\u0e25\\u0e37\\u0e2d\\u0e01\\u0e42\\u0e17\\u0e29/\\u0e1c\\u0e25\\u0e01\\u0e23\\u0e30\\u0e17\\u0e1a\\u0e01\\u0e23\\u0e13\\u0e35\\u0e44\\u0e21\\u0e48\\u0e1b\\u0e0f\\u0e34\\u0e1a\\u0e31\\u0e15\\u0e34\\u0e15\\u0e32\\u0e21\\u0e01\\u0e0e\\u0e2b\\u0e21\\u0e32\\u0e22/\\u0e01\\u0e0e\\u0e40\\u0e01\\u0e13\\u0e11\\u0e4c \\u0e40\\u0e1b\\u0e47\\u0e19 \\\"\\u0e42\\u0e17\\u0e29\\u0e1b\\u0e23\\u0e31\\u0e1a\\\")\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\u0e44\\u0e21\\u0e48\\u0e23\\u0e30\\u0e1a\\u0e38\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "summary_LV4_AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIGoPMH5tw8n"
      },
      "source": [
        "# **Chunking for big PDF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwilwekcQksV"
      },
      "outputs": [],
      "source": [
        "# def split_into_chunks(text, max_chars=3000, overlap=300):\n",
        "#     i = 0\n",
        "#     n = len(text)\n",
        "#     while i < n:\n",
        "#         j = min(i + max_chars, n)\n",
        "#         # พยายามตัดที่ขอบบรรทัด/ช่องว่าง เพื่อลดการตัดกลางประโยค\n",
        "#         slice_ = text[i:j]\n",
        "#         cut = max(slice_.rfind(\"\\n\"), slice_.rfind(\" \"))\n",
        "#         if cut < int(max_chars * 0.5):  # ถ้าหาไม่ได้ ยอมตัดตรง ๆ\n",
        "#             cut = len(slice_)\n",
        "#         yield slice_[:cut]\n",
        "#         i += cut - overlap if (i + cut) < n else n\n",
        "\n",
        "# MAP_PROMPT = \"\"\"คุณเป็นระบบสกัดข้อมูลกฎหมาย/ประกาศ\n",
        "# จงอ่านข้อความต่อไปนี้ (ส่วนหนึ่งของเอกสารใหญ่) แล้วส่งคืนเฉพาะ JSON *เพียว ๆ* ที่มีเฉพาะคีย์ที่พบจริง ไม่ต้องส่งคีย์ที่ไม่พบ\n",
        "\n",
        "# ข้อกำหนด:\n",
        "# - ห้ามมีข้อความอื่นนอกจาก JSON\n",
        "# - ถ้าข้อมูลเป็น “รายการ” ให้คืนเป็นลิสต์ของ string\n",
        "# - ใส่ \"chunk_id\" ด้วย\n",
        "\n",
        "# ต้องการคีย์ดังนี้ (ส่งเฉพาะที่พบ):\n",
        "#     - \"Law/Regulation Name\": เรื่องของประกาศ (เช่น การปรับปรุงหลักเกณฑ์...)\n",
        "#     - \"Source Type\": ประเภทของประกาศ (กฎเกณฑ์/กฎหมาย)\n",
        "#     - \"Regulator Name\": หน่วยงานที่ออกประกาศ (เช่น ธนาคารแห่งประเทศไทย, สำนักงาน ก.ล.ต.)\n",
        "#     - \"Sequenced Number of Regulation\": เลขของประกาศ (เช่น ประกาศธนาคารแห่งปรเทศไทยที่ 19/2568)\n",
        "#     - \"Effective Date\": วันที่มีผลบังคับใช้ (ถ้าไม่พบ ให้ระบุว่า 'ไม่ระบุ')\n",
        "#     - \"Objectives of the Law/Regulation/Announcements\": สรุปสาระสำคัญของประกาศ\n",
        "#     - \"Summary of Important Changes\": สรุปสาระสำคัญที่มีการเปลี่ยนแปลง (สรุปเป็นข้อๆ ถ้ามี)\n",
        "#     - \"Citation Name\": หลักเกณฑ์ในประกาศ (สรุปเป็นข้อๆ ถ้ามี ถ้าไม่พบ ให้ระบุว่า 'ไม่ระบุ')\n",
        "#     - \"Citation Description\": รายละเอียดของหลักเกณฑ์ (ถ้ามีระบุ)\n",
        "#     - \"สิ่งที่ธนาคารต้องดำเนินการ\": สรุปสาระสำคัญที่ธนาคารพาณิชย์ต้องดำเนินการเพื่อให้สอดคล้องกับประกาศฉบับนี้  (สรุปเป็นข้อๆ ถ้ามี)\n",
        "\n",
        "# === TEXT START ===\n",
        "# {chunk}\n",
        "# === TEXT END ===\n",
        "# คืนค่าเป็น JSON เพียว ๆ เท่านั้น\"\"\"\n",
        "\n",
        "# def call_llm_json(llm, prompt, max_retries=2, sleep=1.0):\n",
        "#     last_err = None\n",
        "#     for _ in range(max_retries+1):\n",
        "#         try:\n",
        "#             resp = llm.invoke(prompt)\n",
        "#             txt = resp.content if hasattr(resp, \"content\") else str(resp)\n",
        "#             # ล้างโค้ดเฟนซ์/ป้าย json ที่ชอบติดมา\n",
        "#             txt = txt.strip()\n",
        "#             if txt.startswith(\"```\"):\n",
        "#                 txt = txt.strip(\"`\")\n",
        "#                 txt = re.sub(r\"^json\", \"\", txt, flags=re.I).strip()\n",
        "#             # ดึงเฉพาะ { ... } ก้อนแรก/สุดท้าย เผื่อมี noise\n",
        "#             m1 = txt.find(\"{\"); m2 = txt.rfind(\"}\")\n",
        "#             if m1 != -1 and m2 != -1 and m2 > m1:\n",
        "#                 txt = txt[m1:m2+1]\n",
        "#             data = json.loads(txt)\n",
        "#             return data\n",
        "#         except Exception as e:\n",
        "#             last_err = e\n",
        "#             time.sleep(sleep)\n",
        "#     raise last_err\n",
        "\n",
        "# DATE_PAT = re.compile(r\"(\\d{1,2}\\s*[/-]\\s*\\d{1,2}\\s*[/-]\\s*\\d{2,4}|\\d{1,2}\\s*[ก-ฮ]+\\s*\\d{4}|[0-3]?\\d\\s*(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\s*\\d{4})\", re.I)\n",
        "\n",
        "# def parse_date_any(s):\n",
        "#     s = s.strip()\n",
        "#     # ลองหลายรูปแบบแบบหลวม ๆ\n",
        "#     for fmt in [\"%d/%m/%Y\", \"%d-%m-%Y\", \"%d/%m/%y\", \"%d-%m-%y\", \"%d %b %Y\", \"%d %B %Y\"]:\n",
        "#         try:\n",
        "#             return datetime.strptime(s, fmt)\n",
        "#         except:\n",
        "#             pass\n",
        "#     # ถ้าจับไทย เช่น \"1 มกราคม 2567\" → ข้ามไว้หรือต้องใช้ lib เพิ่ม\n",
        "#     return None\n",
        "\n",
        "# def reduce_chunks(json_list):\n",
        "#     # รวบรวมสถิติ\n",
        "#     single_keys = [\n",
        "#         \"Law/Regulation Name\", \"Source Type\", \"Regulator Name\", \"Sequenced Number of Regulation\"\n",
        "#     ]\n",
        "#     list_keys = [\n",
        "#         \"Objectives of the Law/Regulation/Announcements\",\n",
        "#         \"Summary of Important Changes\",\n",
        "#         \"Citation Name\",\n",
        "#         \"Citation Description\",\n",
        "#         \"สิ่งที่ธนาคารต้องดำเนินการ\"\n",
        "#     ]\n",
        "#     singles = {k: Counter() for k in single_keys}\n",
        "#     lists = {k: [] for k in list_keys}\n",
        "#     dates = []\n",
        "\n",
        "#     for obj in json_list:\n",
        "#         if not isinstance(obj, dict):\n",
        "#             continue\n",
        "#         # singles\n",
        "#         for k in single_keys:\n",
        "#             v = obj.get(k)\n",
        "#             if v and isinstance(v, str) and v.strip() and v.strip() != \"ไม่พบข้อมูล\":\n",
        "#                 singles[k][v.strip()] += 1\n",
        "#         # lists\n",
        "#         for k in list_keys:\n",
        "#             v = obj.get(k)\n",
        "#             if isinstance(v, list):\n",
        "#                 for item in v:\n",
        "#                     if isinstance(item, str):\n",
        "#                         s = item.strip()\n",
        "#                         if s:\n",
        "#                             lists[k].append(s)\n",
        "#         # date\n",
        "#         v = obj.get(\"Effective Date\")\n",
        "#         if isinstance(v, str) and v.strip() and v.strip() != \"ไม่พบข้อมูล\":\n",
        "#             # เก็บทั้ง raw และ parsed\n",
        "#             dt = parse_date_any(v) or None\n",
        "#             dates.append((v.strip(), dt))\n",
        "\n",
        "#     # เลือกค่าที่พบบ่อยสุด\n",
        "#     final = {}\n",
        "#     for k in single_keys:\n",
        "#         if singles[k]:\n",
        "#             final[k] = singles[k].most_common(1)[0][0]\n",
        "#         else:\n",
        "#             final[k] = \"ไม่พบข้อมูล\"\n",
        "\n",
        "#     # Effective Date: ถ้ามีหลายแบบ เลือกที่ parse ได้และเก่าสุด; ถ้า parse ไม่ได้เลย เลือก raw ตัวที่พบบ่อยสุด\n",
        "#     if dates:\n",
        "#         parsed = [d for d in dates if d[1] is not None]\n",
        "#         if parsed:\n",
        "#             parsed.sort(key=lambda x: x[1])\n",
        "#             final[\"Effective Date\"] = parsed[0][0]\n",
        "#         else:\n",
        "#             raw_counter = Counter([d[0] for d in dates])\n",
        "#             final[\"Effective Date\"] = raw_counter.most_common(1)[0][0]\n",
        "#     else:\n",
        "#         final[\"Effective Date\"] = \"ไม่พบข้อมูล\"\n",
        "\n",
        "#     # รวมลิสต์ + ลบซ้ำ (preserve order)\n",
        "#     def dedup(seq):\n",
        "#         seen = set()\n",
        "#         out = []\n",
        "#         for s in seq:\n",
        "#             if s not in seen:\n",
        "#                 seen.add(s)\n",
        "#                 out.append(s)\n",
        "#         return out\n",
        "\n",
        "#     for k in list_keys:\n",
        "#         val = dedup(lists[k])\n",
        "#         final[k] = val if val else [\"ไม่พบข้อมูล\"]\n",
        "\n",
        "#     return final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DIyYQWauZJA"
      },
      "source": [
        "# **LLM Calling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27qBgujx7uQi"
      },
      "outputs": [],
      "source": [
        "# # ========= CASE 1: ใช้กับข้อความสั้น =========\n",
        "# def get_structured_data_from_ai(text, llm):\n",
        "#     prompt = f\"\"\"\n",
        "#     วิเคราะห์ข้อความจากเอกสารกฎหมายต่อไปนี้ และสกัดข้อมูลเพื่อเติมลงในช่องว่างของหนังสือเวียน:\n",
        "\n",
        "#     --- TEXT START ---\n",
        "#     {text}\n",
        "#     --- TEXT END ---\n",
        "\n",
        "#     กรุณาสกัดข้อมูลสำหรับหัวข้อต่อไปนี้ และตอบกลับเป็นรูปแบบ JSON ที่ถูกต้องเท่านั้น:\n",
        "#     - \"Law/Regulation Name\": เรื่องของประกาศ (เช่น การปรับปรุงหลักเกณฑ์...)\n",
        "#     - \"Source Type\": ประเภทของประกาศ (กฎเกณฑ์/กฎหมาย)\n",
        "#     - \"Regulator Name\": หน่วยงานที่ออกประกาศ (เช่น ธนาคารแห่งประเทศไทย, สำนักงาน ก.ล.ต.)\n",
        "#     - \"Sequenced Number of Regulation\": เลขของประกาศ (เช่น ประกาศธนาคารแห่งปรเทศไทยที่ 19/2568)\n",
        "#     - \"Effective Date\": วันที่มีผลบังคับใช้ (ถ้าไม่พบ ให้ระบุว่า 'ไม่ระบุ')\n",
        "#     - \"Objectives of the Law/Regulation/Announcements\": สรุปสาระสำคัญของประกาศ\n",
        "#     - \"Summary of Important Changes\": สรุปสาระสำคัญที่มีการเปลี่ยนแปลง (สรุปเป็นข้อๆ ถ้ามี)\n",
        "#     - \"Citation Name\": หลักเกณฑ์ในประกาศ (สรุปเป็นข้อๆ ถ้ามี ถ้าไม่พบ ให้ระบุว่า 'ไม่ระบุ')\n",
        "#     - \"Citation Description\": รายละเอียดของหลักเกณฑ์ (ถ้ามีระบุ)\n",
        "#     - \"สิ่งที่ธนาคารต้องดำเนินการ\": สรุปสาระสำคัญที่ธนาคารพาณิชย์ต้องดำเนินการเพื่อให้สอดคล้องกับประกาศฉบับนี้  (สรุปเป็นข้อๆ ถ้ามี)\n",
        "\n",
        "#     ถ้าหาข้อมูลส่วนไหนไม่เจอจริงๆ ให้ใส่ค่าเป็น \"ไม่พบข้อมูล\" ใน JSON.\n",
        "#     \"\"\"\n",
        "\n",
        "#     response = llm.invoke(prompt)\n",
        "#     cleaned = response.content.strip().replace('```','').replace('json','')\n",
        "#     log_message(\"✅ Processing finished successfully.\")\n",
        "#     return json.loads(cleaned)\n",
        "\n",
        "\n",
        "# # ========= CASE 2: ใช้กับข้อความยาว =========\n",
        "# # (ต้องมีฟังก์ชัน split_into_chunks, call_llm_json, reduce_chunks ตามที่ผมให้ไปก่อนหน้า)\n",
        "\n",
        "# def get_structured_data_from_ai_large(text, llm):\n",
        "#     map_results = []\n",
        "#     for i, chunk in enumerate(split_into_chunks(text, max_chars=3000, overlap=300), start=1):\n",
        "#         prompt = MAP_PROMPT.format(chunk=chunk)\n",
        "#         try:\n",
        "#             data = call_llm_json(llm, prompt)\n",
        "#             data[\"chunk_id\"] = i\n",
        "#             map_results.append(data)\n",
        "#         except Exception as e:\n",
        "#             map_results.append({\"chunk_id\": i, \"error\": str(e)})\n",
        "\n",
        "#     clean_results = [x for x in map_results if \"error\" not in x]\n",
        "#     if not clean_results:\n",
        "#         return {\"error\": \"AI ไม่สามารถสกัดข้อมูลได้เลย\"}\n",
        "\n",
        "#     final_json = reduce_chunks(clean_results)\n",
        "#     log_message(\"✅ Processing finished successfully.\")\n",
        "#     return final_json\n",
        "\n",
        "\n",
        "# # ========= CASE SELECTOR =========\n",
        "# def extract_structured_data(text, llm, threshold=5000):\n",
        "#     \"\"\"\n",
        "#     ถ้า text ยาวเกิน threshold ตัวอักษร -> ใช้ map-reduce\n",
        "#     ถ้า text สั้น -> ใช้แบบปกติ\n",
        "#     \"\"\"\n",
        "#     if len(text) <= threshold:\n",
        "#         return get_structured_data_from_ai(text, llm)\n",
        "#     else:\n",
        "#         return get_structured_data_from_ai_large(text, llm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JI1dCp8GoKL"
      },
      "source": [
        "Backup create Keyword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWrwXuE5Gnb0"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import re\n",
        "# import json\n",
        "# import time\n",
        "# import random\n",
        "# from datetime import datetime\n",
        "# from typing import List, Tuple, Optional, Dict, Any\n",
        "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# # ====== CONFIG ======\n",
        "# FALLBACK_MODELS = [\n",
        "#     \"gemini-2.5-flash\",       # ตัวหลัก เริ่มจากตัวนี้เสมอทุกครั้งที่เรียก\n",
        "#     \"gemini-2.5-flash-lite\",\n",
        "#     \"gemini-2.0-flash\",\n",
        "#     \"gemini-2.0-flash-lite\",\n",
        "#     \"gemini-1.5-flash\",\n",
        "# ]\n",
        "# DEFAULT_MAX_RETRIES_PER_MODEL = 1         # เราเลือกลองสั้น ๆ แล้วข้ามไปตัวถัดไป\n",
        "# DEFAULT_GLOBAL_TIMEOUT_SEC = 180\n",
        "\n",
        "# def log_message(msg: str):\n",
        "#     print(f\"[{datetime.now().isoformat()}] {msg}\")\n",
        "\n",
        "# # ====== ERROR / RETRY HELPERS ======\n",
        "# def parse_retry_delay_seconds(error_text: str) -> Optional[int]:\n",
        "#     m = re.search(r\"retry_delay\\s*\\{\\s*seconds:\\s*(\\d+)\", error_text)\n",
        "#     if m: return int(m.group(1))\n",
        "#     m = re.search(r'\"retry_delay\"\\s*:\\s*\\{\\s*\"seconds\"\\s*:\\s*(\\d+)', error_text)\n",
        "#     if m: return int(m.group(1))\n",
        "#     try:\n",
        "#         d = json.loads(error_text)\n",
        "#         if isinstance(d, dict):\n",
        "#             rd = d.get(\"retry_delay\") or {}\n",
        "#             secs = rd.get(\"seconds\")\n",
        "#             if isinstance(secs, int): return secs\n",
        "#     except Exception:\n",
        "#         pass\n",
        "#     return None\n",
        "\n",
        "# def is_quota_or_rate_limit_error(e: Exception) -> bool:\n",
        "#     txt = str(e)\n",
        "#     keys = [\"429\", \"ResourceExhausted\", \"rate limit\", \"quota\", \"exceeded\"]\n",
        "#     return any(k.lower() in txt.lower() for k in keys)\n",
        "\n",
        "# # ====== COOLDOWN REGISTRY (ข้ามคำสั่งเรียกได้ในโปรเซสเดียว) ======\n",
        "# _MODEL_COOLDOWN_UNTIL: Dict[str, float] = {}\n",
        "\n",
        "# def _now() -> float:\n",
        "#     return time.time()\n",
        "\n",
        "# def _is_on_cooldown(model: str) -> bool:\n",
        "#     return _MODEL_COOLDOWN_UNTIL.get(model, 0) > _now()\n",
        "\n",
        "# def _set_cooldown(model: str, seconds: float):\n",
        "#     _MODEL_COOLDOWN_UNTIL[model] = max(_MODEL_COOLDOWN_UNTIL.get(model, 0), _now() + seconds)\n",
        "\n",
        "# def _soonest_cooldown_remaining(models: List[str]) -> float:\n",
        "#     if not models: return 0\n",
        "#     t = min((_MODEL_COOLDOWN_UNTIL.get(m, 0) for m in models), default=0)\n",
        "#     remain = t - _now()\n",
        "#     return remain if remain > 0 else 0\n",
        "\n",
        "# # ====== LLM INIT (ครั้งที่ต้องการ instance ถาวร) ======\n",
        "# def init_llm_with_fallback(api_key: str, models: List[str] = FALLBACK_MODELS) -> Tuple[ChatGoogleGenerativeAI, str]:\n",
        "#     last_err = None\n",
        "#     for model in models:\n",
        "#         try:\n",
        "#             llm = ChatGoogleGenerativeAI(model=model, google_api_key=api_key)\n",
        "#             log_message(f\"✅ Initialized model: {model}\")\n",
        "#             return llm, model\n",
        "#         except Exception as e:\n",
        "#             last_err = e\n",
        "#             log_message(f\"⚠️ Init failed for {model}: {e}\")\n",
        "#     raise RuntimeError(f\"❌ No available model. Last error: {last_err}\")\n",
        "\n",
        "# # ====== CIRCULAR INVOKE (เริ่มที่ตัวหลักเสมอ + คูลดาวน์ + วนลูป) ======\n",
        "# def circular_invoke_with_cooldown(\n",
        "#     api_key: str,\n",
        "#     prompt: str,\n",
        "#     models: List[str] = FALLBACK_MODELS,\n",
        "#     max_retries_per_model: int = DEFAULT_MAX_RETRIES_PER_MODEL,\n",
        "#     global_timeout_sec: int = DEFAULT_GLOBAL_TIMEOUT_SEC,\n",
        "#     no_model_sleep_floor: float = 1.5,\n",
        "#     no_model_sleep_cap: float = 30.0,\n",
        "# ):\n",
        "#     \"\"\"\n",
        "#     พฤติกรรม:\n",
        "#       - ทุกครั้งเริ่มจาก models[0] เสมอ (ตัวหลัก)\n",
        "#       - ถ้าเจอโควต้า/429 แล้วมี retry_delay → set cooldown ให้โมเดลนั้น แล้ว 'ข้ามไปตัวถัดไป'\n",
        "#       - ถ้าลองครบทุกตัวและทุกตัวอยู่ในคูลดาวน์ → รอจนตัวที่ใกล้หมดคูลดาวน์ที่สุด (ไม่ต่ำกว่า floor และไม่เกิน cap) แล้วเริ่มใหม่จากตัวหลัก\n",
        "#       - เกิน global timeout → โยน TimeoutError\n",
        "#     \"\"\"\n",
        "#     start = time.time()\n",
        "#     last_error = None\n",
        "#     n = len(models)\n",
        "\n",
        "#     def _try_model(m: str):\n",
        "#         nonlocal last_error\n",
        "#         if _is_on_cooldown(m):\n",
        "#             return None, \"cooldown\"\n",
        "\n",
        "#         try:\n",
        "#             llm = ChatGoogleGenerativeAI(model=m, google_api_key=api_key)\n",
        "#         except Exception as e:\n",
        "#             last_error = e\n",
        "#             log_message(f\"⚠️ Cannot init {m}: {e}\")\n",
        "#             _set_cooldown(m, 5)  # กันลูป\n",
        "#             return None, \"init-fail\"\n",
        "\n",
        "#         for attempt in range(1, max_retries_per_model + 1):\n",
        "#             if time.time() - start > global_timeout_sec:\n",
        "#                 raise TimeoutError(\"⏱️ Global timeout exceeded\")\n",
        "#             try:\n",
        "#                 log_message(f\"🎯 Using model: {m} (attempt {attempt})\")\n",
        "#                 resp = llm.invoke(prompt)\n",
        "#                 return resp, \"ok\"\n",
        "#             except Exception as e:\n",
        "#                 last_error = e\n",
        "#                 if is_quota_or_rate_limit_error(e):\n",
        "#                     delay = parse_retry_delay_seconds(str(e))\n",
        "#                     if delay is None:\n",
        "#                         delay = min(2 ** (attempt - 1), 16) + random.uniform(0, 0.5)\n",
        "#                     _set_cooldown(m, delay)\n",
        "#                     log_message(f\"⏳ {m} quota/rate-limit → cooldown {delay:.1f}s, move on\")\n",
        "#                     return None, \"rate-limit\"\n",
        "#                 else:\n",
        "#                     log_message(f\"❌ {m} non-rate-limit error: {e}\")\n",
        "#                     _set_cooldown(m, 3)\n",
        "#                     return None, \"non-quota-error\"\n",
        "#         return None, \"exhausted\"\n",
        "\n",
        "#     while True:\n",
        "#         if time.time() - start > global_timeout_sec:\n",
        "#             raise TimeoutError(f\"⏱️ Global timeout exceeded. Last error: {last_error}\")\n",
        "\n",
        "#         made_any_attempt = False\n",
        "#         for m in models:  # เริ่มจากตัวแรกเสมอ\n",
        "#             resp, status = _try_model(m)\n",
        "#             if status == \"ok\":\n",
        "#                 return resp, m\n",
        "#             if status != \"cooldown\":\n",
        "#                 made_any_attempt = True\n",
        "\n",
        "#         if not made_any_attempt:\n",
        "#             wait_for = _soonest_cooldown_remaining(models)\n",
        "#             wait_for = max(wait_for, no_model_sleep_floor)\n",
        "#             wait_for = min(wait_for, no_model_sleep_cap)\n",
        "#             log_message(f\"😴 all models cooling down → sleep {wait_for:.1f}s\")\n",
        "#             time.sleep(wait_for)\n",
        "#         else:\n",
        "#             # มีความพยายามแล้วแต่ยังไม่สำเร็จ → วนใหม่เริ่มที่ตัวหลัก\n",
        "#             continue\n",
        "\n",
        "# # ====== JSON-SAFE WRAPPER (ใช้ circular fallback) ======\n",
        "# def _clean_json_block(text: str) -> str:\n",
        "#     cleaned = text.strip()\n",
        "#     cleaned = cleaned.replace(\"```json\", \"```\").strip()\n",
        "#     cleaned = cleaned.strip(\"`\").strip()\n",
        "#     if cleaned.lower().startswith(\"json\"):\n",
        "#         cleaned = cleaned[4:].strip()\n",
        "#     return cleaned\n",
        "\n",
        "# def call_llm_json_with_circular_fallback(api_key: str, prompt: str):\n",
        "#     resp, model_used = circular_invoke_with_cooldown(api_key, prompt)\n",
        "#     raw = resp.content if hasattr(resp, \"content\") else str(resp)\n",
        "#     cleaned = _clean_json_block(raw)\n",
        "#     try:\n",
        "#         return json.loads(cleaned), model_used\n",
        "#     except Exception as e:\n",
        "#         raise ValueError(\n",
        "#             f\"JSON parse failed from model {model_used}: {e}\\nRaw (first 600 chars): {cleaned[:600]}\"\n",
        "#         )\n",
        "\n",
        "# # ====== CHUNKING ======\n",
        "# def split_into_chunks(text: str, max_chars: int = 7000, overlap: int = 300) -> List[str]:\n",
        "#     chunks = []\n",
        "#     start = 0\n",
        "#     n = len(text)\n",
        "#     while start < n:\n",
        "#         end = min(start + max_chars, n)\n",
        "#         chunks.append(text[start:end])\n",
        "#         if end >= n:\n",
        "#             break\n",
        "#         start = max(0, end - overlap)\n",
        "#     return chunks\n",
        "\n",
        "# # ====== PROMPTS ======\n",
        "# MAP_PROMPT = \"\"\"คุณคือผู้ช่วยสกัดข้อมูลกฎหมาย/ประกาศ จงอ่านข้อความต่อไปนี้แล้วสกัดข้อมูลเป็น JSON เท่านั้น\n",
        "\n",
        "# --- TEXT START ---\n",
        "# {chunk}\n",
        "# --- TEXT END ---\n",
        "\n",
        "# จงตอบกลับเป็น JSON object ที่มีคีย์ดังนี้:\n",
        "#   - \"Law/Regulation Name\": เลขของประกาศตามด้วย เรื่องของประกาศ (เช่น การปรับปรุงหลักเกณฑ์...)\n",
        "#   - \"Source Type\": ประเภทของประกาศ (ระบุได้แค่ \"กฎเกณฑ์\" หรือ \"กฎหมาย\" เท่านั้น)\n",
        "#   - \"Regulator Name\": หน่วยงานที่ออกประกาศ (เช่น ธนาคารแห่งประเทศไทย, สำนักงาน ก.ล.ต.)\n",
        "#   - \"Sequenced Number of Regulation\": เลขของประกาศ (เช่น \"ประกาศธนาคารแห่งประเทศไทยที่ 19/2568\" หรือ \"สนส. 12/2555\")\n",
        "#   - \"Effective Date\": วันที่มีผลบังคับใช้ (ถ้าไม่พบ ให้ระบุว่า \"ไม่ระบุ\")\n",
        "#   - \"Objectives of the Law/Regulation/Announcements\": สรุปสาระสำคัญของประกาศ\n",
        "#   - \"Summary of Important Changes\": สรุปสาระสำคัญที่มีการเปลี่ยนแปลง (สรุปเป็นข้อๆ ถ้ามี)\n",
        "#   - \"Citation Name\": หลักเกณฑ์ในประกาศ (สรุปเป็นข้อๆ ไม่เกิน 100 ตัวอักษร ถ้าไม่พบ ให้ \"ไม่ระบุ\")\n",
        "#   - \"Citation Description\": รายละเอียดของหลักเกณฑ์ (ถ้ามี)\n",
        "#   - \"สิ่งที่ธนาคารต้องดำเนินการ\": สิ่งที่ธนาคารพาณิชย์ต้องทำให้สอดคล้องกับประกาศ (สรุปเป็นข้อๆ ถ้ามี)\n",
        "#   - \"Keyword\": อาร์เรย์ของคำสำคัญเชิงกฎเกณฑ์/ความเสี่ยง/กระบวนการ/เอนทิตี (อย่างน้อย 8 คำ สูงสุด 20 คำ) เช่น [\"ธนาคาร\",\"banking\",\"สินเชื่อ\",\"credit\",\"เงินกองทุน\",\"capital\",\"กลุ่มธุรกิจ\",\"การกำกับดูแล\"]\n",
        "\n",
        "# กติกาการทำ \"Keyword\":\n",
        "#   1) ให้คัดคำที่สื่อถึงหัวข้อกฎเกณฑ์ ประเภทความเสี่ยง ชื่อมาตรการ ชื่อกระบวนการ คำย่อ และเอนทิตี (เช่น หน่วยงาน มาตรา/ข้อ)\n",
        "#   2) ใช้ทั้งไทยและอังกฤษเมื่อพบในเอกสาร (อังกฤษให้เป็นตัวพิมพ์เล็ก ยกเว้นคำย่อให้คงรูปพิมพ์ใหญ่ เช่น KYC, AML)\n",
        "#   3) คำแต่ละตัวสั้น กระชับ ไม่เกิน 3 คำ (เช่น \"การยืนยันตัวตน\", \"risk management\", \"consent\")\n",
        "#   4) ตัดคำซ้ำและคำทั่วๆไปที่ไม่ช่วยค้นหา (เช่น “และ”, “หรือ”)\n",
        "#   5) จัดลำดับจากสำคัญสุด -> รองลงมา ตามเนื้อหาเอกสาร\n",
        "\n",
        "# ข้อกำหนด:\n",
        "# - ถ้าไม่พบข้อมูลบางคีย์ ให้ใส่ \"ไม่พบข้อมูล\"\n",
        "# - ต้องเป็น JSON ที่ parse ได้เท่านั้น ห้ามมีข้อความอื่นปะปน\n",
        "# \"\"\"\n",
        "\n",
        "# REDUCE_PROMPT = \"\"\"รวมผล JSON หลายชิ้นให้เป็น JSON เดียว โดยคง schema เดิมทุก Keys\n",
        "# กฏการรวม:\n",
        "# - สำหรับฟิลด์ตัวอักษร: เลือกค่าที่ให้ภาพรวมดีที่สุด ถ้าหลายค่าไม่ขัดแย้งให้รวมสั้น ๆ เป็นข้อความเดียว\n",
        "# - สำหรับ list เช่น \"Summary of Important Changes\", \"Citation Name\", \"สิ่งที่ธนาคารต้องดำเนินการ\":\n",
        "#   รวมและลบรายการซ้ำ\n",
        "# - สรุปใจความสำคัญของแต่ละ Field อีกครั้งเพื่อความกระชับ และเพื่อประหยัดพื้นที่ในการจัดเก็บ\n",
        "# - ถ้าฟิลด์ใดทั้งหมดเป็น \"ไม่พบข้อมูล\" ให้คง \"ไม่พบข้อมูล\"\n",
        "\n",
        "# จงตอบกลับเป็น JSON เท่านั้น\n",
        "\n",
        "# --- PARTS START ---\n",
        "# {parts}\n",
        "# --- PARTS END ---\n",
        "# \"\"\"\n",
        "\n",
        "# def merge_lists_unique(*lists) -> List[str]:\n",
        "#     out = []\n",
        "#     seen = set()\n",
        "#     for lst in lists:\n",
        "#         if isinstance(lst, list):\n",
        "#             for item in lst:\n",
        "#                 if isinstance(item, str):\n",
        "#                     key = item.strip()\n",
        "#                     if key and key not in seen:\n",
        "#                         seen.add(key)\n",
        "#                         out.append(key)\n",
        "#     return out\n",
        "\n",
        "# def reduce_chunks(parts: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "#     fields_text = [\n",
        "#         \"Law/Regulation Name\",\n",
        "#         \"Source Type\",\n",
        "#         \"Regulator Name\",\n",
        "#         \"Sequenced Number of Regulation\",\n",
        "#         \"Effective Date\",\n",
        "#         \"Objectives of the Law/Regulation/Announcements\",\n",
        "#         \"Citation Description\",\n",
        "#     ]\n",
        "#     fields_list = [\n",
        "#         \"Summary of Important Changes\",\n",
        "#         \"Citation Name\",\n",
        "#         \"สิ่งที่ธนาคารต้องดำเนินการ\",\n",
        "#     ]\n",
        "\n",
        "#     agg: Dict[str, Any] = {k: \"ไม่พบข้อมูล\" for k in fields_text}\n",
        "#     for k in fields_list:\n",
        "#         agg[k] = []\n",
        "\n",
        "#     candidates: Dict[str, List[str]] = {k: [] for k in fields_text}\n",
        "\n",
        "#     for p in parts:\n",
        "#         for k in fields_text:\n",
        "#             v = p.get(k)\n",
        "#             if isinstance(v, str) and v.strip() and v.strip() != \"ไม่พบข้อมูล\":\n",
        "#                 candidates[k].append(v.strip())\n",
        "#         for k in fields_list:\n",
        "#             v = p.get(k)\n",
        "#             if isinstance(v, list):\n",
        "#                 agg[k] = merge_lists_unique(agg[k], v)\n",
        "\n",
        "#     for k in fields_text:\n",
        "#         if candidates[k]:\n",
        "#             agg[k] = max(candidates[k], key=len)\n",
        "#     return agg\n",
        "\n",
        "# # ====== CASE 1: ข้อความสั้น → ขอ JSON ตรง ๆ (ใช้วงกลม) ======\n",
        "# def get_structured_data_from_ai(text: str) -> Dict[str, Any]:\n",
        "#     prompt = f\"\"\"\n",
        "#     วิเคราะห์ข้อความจากเอกสารกฎหมายต่อไปนี้ และสกัดข้อมูลเพื่อเติมลงในช่องว่างเพื่อจัดเก็บประกาศ:\n",
        "\n",
        "#     --- TEXT START ---\n",
        "#     {text}\n",
        "#     --- TEXT END ---\n",
        "\n",
        "#     จงตอบกลับเป็น JSON object ที่มีคีย์ดังนี้:\n",
        "#   - \"Law/Regulation Name\": เลขของประกาศตามด้วย เรื่องของประกาศ (เช่น การปรับปรุงหลักเกณฑ์...)\n",
        "#   - \"Source Type\": ประเภทของประกาศ (ระบุได้แค่ \"กฎเกณฑ์\" หรือ \"กฎหมาย\" เท่านั้น)\n",
        "#   - \"Regulator Name\": หน่วยงานที่ออกประกาศ (เช่น ธนาคารแห่งประเทศไทย, สำนักงาน ก.ล.ต.)\n",
        "#   - \"Sequenced Number of Regulation\": เลขของประกาศ (เช่น \"ประกาศธนาคารแห่งประเทศไทยที่ 19/2568\" หรือ \"สนส. 12/2555\")\n",
        "#   - \"Effective Date\": วันที่มีผลบังคับใช้ (ถ้าไม่พบ ให้ระบุว่า \"ไม่ระบุ\")\n",
        "#   - \"Objectives of the Law/Regulation/Announcements\": สรุปสาระสำคัญของประกาศ\n",
        "#   - \"Summary of Important Changes\": สรุปสาระสำคัญที่มีการเปลี่ยนแปลง (สรุปเป็นข้อๆ ถ้ามี)\n",
        "#   - \"Citation Name\": หลักเกณฑ์ในประกาศ (สรุปเป็นข้อๆ ไม่เกิน 100 ตัวอักษร ถ้าไม่พบ ให้ \"ไม่ระบุ\")\n",
        "#   - \"Citation Description\": รายละเอียดของหลักเกณฑ์ (ถ้ามี)\n",
        "#   - \"สิ่งที่ธนาคารต้องดำเนินการ\": สิ่งที่ธนาคารพาณิชย์ต้องทำให้สอดคล้องกับประกาศ (สรุปเป็นข้อๆ ถ้ามี)\n",
        "#   - \"Keyword\": อาร์เรย์ของคำสำคัญเชิงกฎเกณฑ์/ความเสี่ยง/กระบวนการ/เอนทิตี (อย่างน้อย 8 คำ สูงสุด 20 คำ) เช่น [\"ธนาคาร\",\"banking\",\"สินเชื่อ\",\"credit\",\"เงินกองทุน\",\"capital\",\"กลุ่มธุรกิจ\",\"การกำกับดูแล\"]\n",
        "\n",
        "# กติกาการทำ \"Keyword\":\n",
        "#   1) ให้คัดคำที่สื่อถึงหัวข้อกฎเกณฑ์ ประเภทความเสี่ยง ชื่อมาตรการ ชื่อกระบวนการ คำย่อ และเอนทิตี (เช่น หน่วยงาน มาตรา/ข้อ)\n",
        "#   2) ใช้ทั้งไทยและอังกฤษเมื่อพบในเอกสาร (อังกฤษให้เป็นตัวพิมพ์เล็ก ยกเว้นคำย่อให้คงรูปพิมพ์ใหญ่ เช่น KYC, AML)\n",
        "#   3) คำแต่ละตัวสั้น กระชับ ไม่เกิน 3 คำ (เช่น \"การยืนยันตัวตน\", \"risk management\", \"consent\")\n",
        "#   4) ตัดคำซ้ำและคำทั่วๆไปที่ไม่ช่วยค้นหา (เช่น “และ”, “หรือ”)\n",
        "#   5) จัดลำดับจากสำคัญสุด -> รองลงมา ตามเนื้อหาเอกสาร\n",
        "\n",
        "# ข้อกำหนด:\n",
        "# - ถ้าไม่พบข้อมูลบางคีย์ ให้ใส่ \"ไม่พบข้อมูล\"\n",
        "# - ต้องเป็น JSON ที่ parse ได้เท่านั้น ห้ามมีข้อความอื่นปะปน\n",
        "#     \"\"\"\n",
        "#     data, model_used = call_llm_json_with_circular_fallback(GOOGLE_API_KEY, prompt)\n",
        "#     log_message(f\"✅ Short-text processed by {model_used}\")\n",
        "#     return data\n",
        "\n",
        "# # ====== CASE 2: ข้อความยาว → map-reduce (ใช้วงกลมในแต่ละ chunk) ======\n",
        "# def get_structured_data_from_ai_large(text: str, max_chars=7000, overlap=300) -> Dict[str, Any]:\n",
        "#     map_results = []\n",
        "#     for i, chunk in enumerate(split_into_chunks(text, max_chars=max_chars, overlap=overlap), start=1):\n",
        "#         prompt = MAP_PROMPT.format(chunk=chunk)\n",
        "#         try:\n",
        "#             data, model_used = call_llm_json_with_circular_fallback(GOOGLE_API_KEY, prompt)\n",
        "#             data[\"chunk_id\"] = i\n",
        "#             data[\"_model\"] = model_used\n",
        "#             map_results.append(data)\n",
        "#             log_message(f\"🧩 mapped chunk {i} via {model_used}\")\n",
        "#         except Exception as e:\n",
        "#             log_message(f\"❌ chunk {i} error: {e}\")\n",
        "#             map_results.append({\"chunk_id\": i, \"error\": str(e)})\n",
        "\n",
        "#     clean_results = [x for x in map_results if \"error\" not in x]\n",
        "#     if not clean_results:\n",
        "#         return {\"error\": \"AI ไม่สามารถสกัดข้อมูลได้เลย\"}\n",
        "\n",
        "#     merged = reduce_chunks(clean_results)\n",
        "\n",
        "#     # OPTIONAL: ให้ LLM ช่วยรวมขั้นสุดท้าย\n",
        "#     try:\n",
        "#         reduce_prompt = REDUCE_PROMPT.format(parts=json.dumps(clean_results, ensure_ascii=False, indent=2))\n",
        "#         final_json, model_used = call_llm_json_with_circular_fallback(GOOGLE_API_KEY, reduce_prompt)\n",
        "#         log_message(f\"✅ Reduced via {model_used}\")\n",
        "#         return final_json\n",
        "#     except Exception as e:\n",
        "#         log_message(f\"⚠️ Reduce by LLM failed, fallback to programmatic merge: {e}\")\n",
        "#         return merged\n",
        "\n",
        "# # ====== CASE SELECTOR ======\n",
        "# def extract_structured_data(text: str, *, llm=None, threshold: int = 8000) -> Dict[str, Any]:\n",
        "#     if len(text) <= threshold:\n",
        "#         return get_structured_data_from_ai(text)\n",
        "#     else:\n",
        "#         return get_structured_data_from_ai_large(text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}